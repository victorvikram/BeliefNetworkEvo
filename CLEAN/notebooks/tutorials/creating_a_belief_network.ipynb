{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello (Preliminaries ðŸˆðŸ˜ºðŸ˜¹)\n",
    "In this Notebook we walk through the creation of a belief network from the raw GSS dataset.\n",
    "\n",
    "As a preliminary, make sure you actally have the raw dataset. It should be located and named as follows: \n",
    "\n",
    ">CLEAN\\datasets\\raw_data\\gss7222_r4.sas7bdat \n",
    "\n",
    "Okay. Now, first we need to import all the functions we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to Python path\n",
    "import os\n",
    "import sys\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath(\"..\")))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# 1. Read in the raw dataset and cache it. \n",
    "#    Note: when we import the dataset, we automatically discard all variables that we're not interested. Edit the function if there are variables you'd like to keep.\n",
    "from CLEAN.datasets.import_gss import import_dataset\n",
    "\n",
    "# 2. Clean the raw dataset and derive special variables we are interested in. \n",
    "#    This involves: \n",
    "#                       a) normalising variables between -1 and 1 and derive special variables.\n",
    "#                       b) derriving new variables from existing ones.\n",
    "from CLEAN.datasets.clean_raw_data import clean_datasets\n",
    "\n",
    "# 3. Calculate the belief network.\n",
    "#    This involves calculating the correlation matrix of the filtered dataset.\n",
    "from CLEAN.source_code.generators.corr_make_network import calculate_correlation_matrix, CorrelationMethod, EdgeSuppressionMethod\n",
    "\n",
    "# 4. Visualize the belief network.\n",
    "#    This involves visualizing the belief network in a graph.\n",
    "from CLEAN.source_code.visualizers.network_visualizer import generate_html_visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the raw dataset ðŸ˜º\n",
    "First we will run a script that filters the dataset down to only the variables we are interested in. \n",
    "Feel free to look at the code in `import_gss.py` to see which variables are included. But keep in mind that if you want to add in more variables, you'll need to manually normalise it in clean_raw_data.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache...\n",
      "Done! âœ¨\n"
     ]
    }
   ],
   "source": [
    "df, _ = import_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the raw dataset ðŸ˜º\n",
    "Next we will run a script that cleans the dataset and derives special variables. \n",
    "\n",
    "This will normalise all the variables between -1 and 1, and derive some special variables like \"VOTELAST_DEMREP\" (this tells you which major party the respondent voted for in the previous election).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache...\n",
      "Done! âœ¨\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timbo\\Github\\BeliefNetworkEvo\\CLEAN\\datasets\\clean_raw_data.py:253: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  series = series.replace(['I', 'N', 'Y'], np.nan)\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = clean_datasets()\n",
    "\n",
    "# This warning is annoying. Will fix later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the belief network ðŸ˜º\n",
    "\n",
    "Now we will run a script that calculates the belief network. This will calculate the correlation matrix of the dataset, and then use that to create a belief network.\n",
    "\n",
    "Here we can specify the years of interest, further filther the variables of interest, specify the method of correlation, whether we want partial correlations, and how we want to suppress edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = calculate_correlation_matrix(\n",
    "    cleaned_df, \n",
    "    years_of_interest=[2018, 2020],\n",
    "    method=CorrelationMethod.PEARSON, \n",
    "    partial=True, \n",
    "    edge_suppression=EdgeSuppressionMethod.REGULARIZATION,\n",
    "    suppression_params={'regularization': 0.18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network visualization has been saved to c:\\Users\\timbo\\Github\\BeliefNetworkEvo\\CLEAN\\notebooks\\tutorials\\delete_this_file.html\n"
     ]
    }
   ],
   "source": [
    "# Create and save network visualization for the final time period        # Create network data\n",
    "generate_html_visualization(\n",
    "    corr_matrix,\n",
    "    highlight_nodes=['POLVIEWS'],\n",
    "    output_path='delete_this_file.html'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
