{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pyreadstat as prs\n",
    "\n",
    "raw_df, meta = prs.read_sas7bdat(\"../dat/GSS_sas/gss7222_r3.sas7bdat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from transform_df_to_our_standard import transform_dataframe, make_variable_summary, make_vote_supernodes\n",
    "from corr_networks import corr_mat_to_partial_corr_mat, cov_mat_to_regularized_partial_corr\n",
    "from triads import count_triads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:490: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['PRES12_DIDNT_VOTE'] = df['PRES12'].map(category_map_D)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:491: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['PRES12_DONT_KNOW'] = df['PRES12'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:492: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:493: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['PRES16_CLINTON'] = df['PRES16'].map(category_map_A)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:494: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['PRES16_TRUMP'] = df['PRES16'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:496: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['PRES16_DIDNT_VOTE'] = df['PRES16'].map(category_map_D)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:497: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['PRES16_DONT_KNOW'] = df['PRES16'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:498: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:499: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['PRES20_BIDEN'] = df['PRES20'].map(category_map_A)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:500: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['PRES20_TRUMP'] = df['PRES20'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:501: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['PRES20_OTHER'] = df['PRES20'].map(category_map_C)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:502: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['PRES20_DIDNT_VOTE'] = df['PRES20'].map(category_map_D)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:504: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:505: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF68WHO_HUMPHREY'] = df['IF68WHO'].map(category_map_A)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:506: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF68WHO_NIXON'] = df['IF68WHO'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:507: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF68WHO_WALLACE'] = df['IF68WHO'].map(category_map_C)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:508: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF68WHO_OTHER'] = df['IF68WHO'].map(category_map_D)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:509: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF68WHO_WLDNT_VT_RELIG'] = df['IF68WHO'].map(category_map_E)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:510: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF68WHO_DONT_KNOW'] = df['IF68WHO'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:512: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF72WHO_MCGOVERN'] = df['IF72WHO'].map(category_map_A)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:513: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF72WHO_NIXON'] = df['IF72WHO'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:514: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF72WHO_OTHER'] = df['IF72WHO'].map(category_map_C)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:515: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF72WHO_REFUSED'] = df['IF72WHO'].map(category_map_D)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:516: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF72WHO_WOULDNT_VOTE'] = df['IF72WHO'].map(category_map_E)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:517: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF72WHO_WLDNT_VT_RELIG'] = df['IF72WHO'].map(category_map_F)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:518: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF72WHO_DONT_KNOW'] = df['IF72WHO'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:520: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF76WHO_CARTER'] = df['IF76WHO'].map(category_map_A)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:521: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF76WHO_FORD'] = df['IF76WHO'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:522: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF76WHO_OTHER'] = df['IF76WHO'].map(category_map_C)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:523: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF76WHO_REFUSED'] = df['IF76WHO'].map(category_map_D)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:524: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF76WHO_WOULDNT_VOTE'] = df['IF76WHO'].map(category_map_E)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:525: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF76WHO_DONT_KNOW'] = df['IF76WHO'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:526: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:528: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF80WHO_REAGAN'] = df['IF80WHO'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:529: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF80WHO_ANDERSON'] = df['IF80WHO'].map(category_map_C)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:530: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF80WHO_OTHER'] = df['IF80WHO'].map(category_map_D)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:531: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF80WHO_WOULDNT_VOTE'] = df['IF80WHO'].map(category_map_E)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:532: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF80WHO_REFUSED'] = df['IF80WHO'].map(category_map_F)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:533: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF80WHO_DONT_KNOW'] = df['IF80WHO'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:534: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:536: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF84WHO_REAGAN'] = df['IF84WHO'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:537: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF84WHO_OTHER'] = df['IF84WHO'].map(category_map_C)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:538: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF84WHO_WOULDNT_VOTE'] = df['IF84WHO'].map(category_map_D)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:539: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF84WHO_DONT_KNOW'] = df['IF84WHO'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:540: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:541: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF88WHO_DUKAKIS'] = df['IF88WHO'].map(category_map_A)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF88WHO_OTHER'] = df['IF88WHO'].map(category_map_C)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:544: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF88WHO_DONT_KNOW'] = df['IF88WHO'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:545: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:546: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF92WHO_CLINTON'] = df['IF92WHO'].map(category_map_A)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:547: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF92WHO_BUSH'] = df['IF92WHO'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:548: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF92WHO_PEROT'] = df['IF92WHO'].map(category_map_C)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:549: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF92WHO_OTHER'] = df['IF92WHO'].map(category_map_D)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:551: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:552: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF96WHO_CLINTON'] = df['IF96WHO'].map(category_map_A)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:553: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF96WHO_DOLE'] = df['IF96WHO'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:554: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF96WHO_PEROT'] = df['IF96WHO'].map(category_map_C)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:555: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF96WHO_OTHER'] = df['IF96WHO'].map(category_map_D)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:556: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF96WHO_DONT_KNOW'] = df['IF96WHO'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:558: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF00WHO_GORE'] = df['IF00WHO'].map(category_map_A)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:559: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF00WHO_BUSH'] = df['IF00WHO'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:560: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF00WHO_NADER'] = df['IF00WHO'].map(category_map_C)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:561: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF00WHO_OTHER'] = df['IF00WHO'].map(category_map_D)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:562: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF00WHO_DONT_KNOW'] = df['IF00WHO'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:563: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:564: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF04WHO_KERRY'] = df['IF04WHO'].map(category_map_A)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:566: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF04WHO_NADER'] = df['IF04WHO'].map(category_map_C)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:567: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF04WHO_DONT_KNOW'] = df['IF04WHO'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:568: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:569: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF08WHO_OBAMA'] = df['IF08WHO'].map(category_map_A)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:570: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF08WHO_MCCAIN'] = df['IF08WHO'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:572: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF08WHO_DONT_KNOW'] = df['IF08WHO'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:573: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:574: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF12WHO_OBAMA'] = df['IF12WHO'].map(category_map_A)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:575: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF12WHO_ROMNEY'] = df['IF12WHO'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:577: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF12WHO_DONT_KNOW'] = df['IF12WHO'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:578: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:579: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF16WHO_CLINTON'] = df['IF16WHO'].map(category_map_A)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:580: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF16WHO_TRUMP'] = df['IF16WHO'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:581: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF16WHO_OTHER'] = df['IF16WHO'].map(category_map_C)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:583: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF16WHO_DONT_KNOW'] = df['IF16WHO'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:584: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:585: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF20WHO_BIDEN'] = df['IF20WHO'].map(category_map_A)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:586: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF20WHO_TRUMP'] = df['IF20WHO'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:587: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF20WHO_OTHER'] = df['IF20WHO'].map(category_map_C)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:589: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['IF20WHO_DONT_KNOW'] = df['IF20WHO'].map(DONT_KNOW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:590: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:591: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['POLVIEWS'] = df['POLVIEWS'].map(POLVIEWS_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:592: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:593: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATSPAC'] = df['NATSPAC'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:595: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATHEAL'] = df['NATHEAL'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:596: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATCITY'] = df['NATCITY'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:597: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATCRIME'] = df['NATCRIME'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:598: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATDRUG'] = df['NATDRUG'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:600: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATRACE'] = df['NATRACE'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:601: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATARMS'] = df['NATARMS'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:602: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATAID'] = df['NATAID'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:603: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATFARE'] = df['NATFARE'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:605: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATSOC'] = df['NATSOC'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:606: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATMASS'] = df['NATMASS'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:607: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATPARK'] = df['NATPARK'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:608: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATCHLD'] = df['NATCHLD'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:610: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATENRGY'] = df['NATENRGY'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:611: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:612: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATSPACY'] = df['NATSPACY'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:613: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATENVIY'] = df['NATENVIY'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:614: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATHEALY'] = df['NATHEALY'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:616: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATCRIMY'] = df['NATCRIMY'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:617: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATDRUGY'] = df['NATDRUGY'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:618: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATEDUCY'] = df['NATEDUCY'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:619: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATRACEY'] = df['NATRACEY'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:620: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATARMSY'] = df['NATARMSY'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:622: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NATFAREY'] = df['NATFAREY'].map(NAT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:624: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['EQWLTH'] = df['EQWLTH'].map(EQWLTH_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:625: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:626: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['SPKATH'] = df['SPKATH'].map(SPK_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:627: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['SPKRAC'] = df['SPKRAC'].map(SPK_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:628: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['SPKCOM'] = df['SPKCOM'].map(SPK_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:629: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['SPKMIL'] = df['SPKMIL'].map(SPK_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:630: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['SPKHOMO'] = df['SPKHOMO'].map(SPK_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:631: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['SPKMSLM'] = df['SPKMSLM'].map(SPK_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:632: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:633: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['COLATH'] = df['COLATH'].map(COLATH_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:634: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['COLRAC'] = df['COLRAC'].map(COLATH_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:635: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['COLCOM'] = df['COLCOM'].map(COLATH_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:636: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['COLMIL'] = df['COLMIL'].map(COLATH_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:637: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['COLHOMO'] = df['COLHOMO'].map(COLATH_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:638: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['COLMSLM'] = df['COLMSLM'].map(COLATH_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:639: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:640: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['LIBATH'] = df['LIBATH'].map(LIB_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:641: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['LIBRAC'] = df['LIBRAC'].map(LIB_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:643: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['LIBMIL'] = df['LIBMIL'].map(LIB_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:644: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['LIBHOMO'] = df['LIBHOMO'].map(LIB_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['LIBMSLM'] = df['LIBMSLM'].map(LIB_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:646: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:647: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['CAPPUN'] = df['CAPPUN'].map(POL1_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:648: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['GUNLAW'] = df['GUNLAW'].map(POL1_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:649: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:650: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['COURTS'] = df['COURTS'].map(COURTS_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:651: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:652: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['GRASS'] = df['GRASS'].map(GRASS_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:653: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:655: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['RELIG_CATHOLIC'] = df['RELIG'].map(category_map_B)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:657: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['RELIG_NONE'] = df['RELIG'].map(category_map_D)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:658: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['RELIG_OTHER'] = df['RELIG'].map(category_map_E)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:659: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['RELIG_BUDDHISM'] = df['RELIG'].map(category_map_F)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:660: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['RELIG_HINDUISM'] = df['RELIG'].map(category_map_G)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:661: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['RELIG_OTHER_EASTERN'] = df['RELIG'].map(category_map_H)  # Adjusted for clarity\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:662: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['RELIG_MUSLIM_ISLAM'] = df['RELIG'].map(category_map_I)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:664: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['RELIG_CHRISTIAN'] = df['RELIG'].map(category_map_K)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:665: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['RELIG_NATIVE_AMERICAN'] = df['RELIG'].map(category_map_L)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:666: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['RELIG_INTER_NONDENOMINATIONAL'] = df['RELIG'].map(category_map_M)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:668: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['ATTEND'] = df['ATTEND'].map(ATTEND_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:669: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:671: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:672: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['POSTLIFE'] = df['POSTLIFE'].map(POSTLIFE_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:673: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:674: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['PRAYER'] = df['PRAYER'].map(PRAYER_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:675: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:676: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['RACOPEN'] = df['RACOPEN'].map(RACOPEN_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:678: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['AFFRMACT'] = df['AFFRMACT'].map(AFFRMACT_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:679: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:681: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:683: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:685: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:686: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['TRUST'] = df['TRUST'].map(TRUST_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:687: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:688: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['CONFINAN'] = df['CONFINAN'].map(CON_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:689: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['CONBUS'] = df['CONBUS'].map(CON_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:690: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['CONCLERG'] = df['CONCLERG'].map(CON_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:691: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['CONEDUC'] = df['CONEDUC'].map(CON_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:692: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['CONFED'] = df['CONFED'].map(CON_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:693: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['CONLABOR'] = df['CONLABOR'].map(CON_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:694: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['CONPRESS'] = df['CONPRESS'].map(CON_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:695: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['CONMEDIC'] = df['CONMEDIC'].map(CON_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:696: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['CONTV'] = df['CONTV'].map(CON_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:697: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['CONJUDGE'] = df['CONJUDGE'].map(CON_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:699: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['CONLEGIS'] = df['CONLEGIS'].map(CON_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:701: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:703: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['POPULAR'] = df['POPULAR'].map(KID_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:705: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['WORKHARD'] = df['WORKHARD'].map(KID_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:707: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:709: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:711: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:713: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['ABNOMORE'] = df['ABNOMORE'].map(AB_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:715: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['ABPOOR'] = df['ABPOOR'].map(AB_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:717: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['ABSINGLE'] = df['ABSINGLE'].map(AB_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:719: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:720: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:721: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['SEXEDUC'] = df['SEXEDUC'].map(SEXEDUC_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:722: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:723: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['DIVLAW'] = df['DIVLAW'].map(DIVLAW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:724: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:725: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['PREMARSX'] = df['PREMARSX'].map(SEX_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:726: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['TEENSEX'] = df['TEENSEX'].map(SEX_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:727: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['XMARSEX'] = df['XMARSEX'].map(SEX_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:728: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['HOMOSEX'] = df['HOMOSEX'].map(SEX_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:729: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:730: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['PORNLAW'] = df['PORNLAW'].map(PORNLAW_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:731: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:733: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:734: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['LETDIE1'] = df['LETDIE1'].map(DEATH_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:735: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['SUICIDE1'] = df['SUICIDE1'].map(DEATH_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:736: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['SUICIDE2'] = df['SUICIDE2'].map(DEATH_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:737: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:739: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['POLABUSE'] = df['POLABUSE'].map(POLICE_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:741: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['POLESCAP'] = df['POLESCAP'].map(POLICE_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:743: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:744: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['NEWS'] = df['NEWS'].map(NEWS_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:745: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:746: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['TVHOURS'] = df['TVHOURS'].map(TVHOURS_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:747: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:748: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['FECHLD'] = df['FECHLD'].map(FE_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:749: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['FEPRESCH'] = df['FEPRESCH'].map(FE_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:752: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['RACDIF1'] = df['RACDIF1'].map(RACDIF_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:754: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['RACDIF3'] = df['RACDIF3'].map(RACDIF_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:756: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:757: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['HELPPOOR'] = df['HELPPOOR'].map(HELP_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:758: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['HELPNOT'] = df['HELPNOT'].map(HELP_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:759: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['HELPBLK'] = df['HELPBLK'].map(HELP_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:761: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df['MARHOMO'] = df['MARHOMO'].map(MARHOMO_map)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:763: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:765: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  for variant, original in variants.items():\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:766: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_column = transformed_df[original].combine_first(transformed_df[variant])\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:767: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df[original] = combined_column\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:769: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  transformed_df = transformed_df.drop(variants.keys(), axis=1)\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:770: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:771: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ### Uncomment this to print select columns to a text file.\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:772: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  # with open('partyid.txt', 'w') as f:\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:773: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  #     for index, row in df.iterrows():\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:775: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:777: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:779: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:780: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:781: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:783: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:784: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:785: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:786: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:788: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:789: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:790: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\Users\\vicvi\\BeliefNetworkEvo\\nbk\\../src\\transform_df_to_our_standard.py:792: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    }
   ],
   "source": [
    "df = transform_dataframe(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.to_list()\n",
    "\"RACOPEN\" in cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_use = [\"PARTYID\",\"POLVIEWS\",\"NATSPAC\",\"NATENVIR\",\"NATHEAL\",\"NATCITY\",\"NATCRIME\",\"NATDRUG\",\"NATEDUC\",\"NATRACE\",\"NATARMS\",\n",
    "\"NATAID\",\"NATFARE\",\"NATROAD\",\"NATSOC\",\"NATMASS\",\"NATPARK\",\"NATCHLD\",\"NATSCI\",\"NATENRGY\",\"NATSPACY\",\"NATENVIY\",\"NATHEALY\",\"NATCITYY\",\"NATCRIMY\",\"NATDRUGY\",\"NATEDUCY\",\n",
    "\"NATRACEY\",\"NATARMSY\",\"NATAIDY\",\"NATFAREY\",\"EQWLTH\",\"SPKATH\",\"COLATH\",\"LIBATH\",\"SPKRAC\",\"COLRAC\",\"LIBRAC\",\"SPKCOM\",\"COLCOM\",\"LIBCOM\",\"SPKMIL\",\"COLMIL\",\"LIBMIL\",\"SPKHOMO\",\n",
    "\"COLHOMO\",\"LIBHOMO\",\"SPKMSLM\",\"COLMSLM\",\"LIBMSLM\",\"CAPPUN\",\"GUNLAW\",\"COURTS\",\"GRASS\",\"ATTEND\",\"RELITEN\",\"POSTLIFE\",\"PRAYER\",\"AFFRMACT\",\"WRKWAYUP\",\"HELPFUL\",\n",
    "\"FAIR\",\"TRUST\",\"CONFINAN\",\"CONBUS\",\"CONCLERG\",\"CONEDUC\",\"CONFED\",\"CONLABOR\",\"CONPRESS\",\"CONMEDIC\",\"CONTV\",\"CONJUDGE\",\"CONSCI\",\"CONLEGIS\",\"CONARMY\",\"GETAHEAD\",\"FEPOL\",\"ABDEFECT\",\"ABNOMORE\",\"ABHLTH\",\"ABPOOR\",\"ABRAPE\",\"ABSINGLE\",\"ABANY\",\"SEXEDUC\",\"DIVLAW\",\"PREMARSX\",\"TEENSEX\",\"XMARSEX\",\"HOMOSEX\",\"PORNLAW\",\n",
    "\"SPANKING\",\"LETDIE1\",\"SUICIDE1\",\"SUICIDE2\",\"POLHITOK\",\"POLABUSE\",\"POLMURDR\",\"POLESCAP\",\"POLATTAK\",\"NEWS\",\"TVHOURS\",\"FECHLD\",\"FEPRESCH\",\"FEFAM\",\"RACDIF1\",\"RACDIF2\",\"RACDIF3\",\n",
    "\"RACDIF4\",\"HELPPOOR\",\"MARHOMO\", \"RACOPEN\", \"HELPNOT\", \"HELPBLK\"]\n",
    "\n",
    "PRES_variables = [\n",
    "    'VOTE68', 'VOTE72', 'VOTE76', 'VOTE80', 'VOTE84', 'VOTE88', 'VOTE92', 'VOTE96', 'VOTE00', 'VOTE04', 'VOTE08', 'VOTE12', 'VOTE16', 'VOTE20',\n",
    "    'VOTE68_ELIGIBLE', 'VOTE72_ELIGIBLE', 'VOTE76_ELIGIBLE', 'VOTE80_ELIGIBLE', 'VOTE84_ELIGIBLE', 'VOTE88_ELIGIBLE', 'VOTE92_ELIGIBLE', 'VOTE96_ELIGIBLE', 'VOTE00_ELIGIBLE', 'VOTE04_ELIGIBLE', 'VOTE08_ELIGIBLE', 'VOTE12_ELIGIBLE', 'VOTE16_ELIGIBLE', 'VOTE20_ELIGIBLE',\n",
    "    'PRES68_HUMPHREY', 'PRES68_NIXON', 'PRES68_WALLACE', 'PRES68_OTHER', 'PRES68_REFUSED', 'PRES68_'\n",
    "    'PRES72_MCGOVERN', 'PRES72_NIXON', 'PRES72_OTHER', 'PRES72_REFUSED', 'PRES72_WOULDNT_VOTE', 'PRES72_DONT_KNOW',\n",
    "    'PRES76_CARTER', 'PRES76_FORD', 'PRES76_OTHER', 'PRES76_REFUSED', 'PRES76_NO_PRES_VOTE', 'PRES76_DONT_KNOW',\n",
    "    'PRES80_CARTER', 'PRES80_REAGAN', 'PRES80_ANDERSON', 'PRES80_OTHER', 'PRES80_REFUSED', 'PRES80_DIDNT_VOTE', 'PRES80_DONT_KNOW',\n",
    "    'PRES84_MONDALE', 'PRES84_REAGAN', 'PRES84_OTHER', 'PRES84_REFUSED', 'PRES84_NO_PRES_VOTE', 'PRES84_DONT_KNOW',\n",
    "    'PRES88_BUSH', 'PRES88_DUKAKIS', 'PRES88_OTHER', 'PRES88_REFUSED', 'PRES88_NO_PRES_VOTE', 'PRES88_DONT_KNOW',\n",
    "    'PRES92_CLINTON', 'PRES92_BUSH', 'PRES92_PEROT', 'PRES92_OTHER', 'PRES92_NO_PRES_VOTE', 'PRES92_DONT_KNOW',\n",
    "    'PRES96_CLINTON', 'PRES96_DOLE', 'PRES96_PEROT', 'PRES96_OTHER', 'PRES96_DIDNT_VOTE', 'PRES96_DONT_KNOW',\n",
    "    'PRES00_GORE', 'PRES00_BUSH', 'PRES00_NADER', 'PRES00_OTHER', 'PRES00_DIDNT_VOTE', 'PRES00_DONT_KNOW',\n",
    "    'PRES04_KERRY', 'PRES04_BUSH', 'PRES04_NADER', 'PRES04_NO_PRES_VOTE', 'PRES04_DONT_KNOW',\n",
    "    'PRES08_OBAMA', 'PRES08_MCCAIN', 'PRES08_OTHER', 'PRES08_DIDNT_VOTE', 'PRES08_DONT_KNOW',\n",
    "    'PRES12_OBAMA', 'PRES12_ROMNEY', 'PRES12_OTHER', 'PRES12_DIDNT_VOTE', 'PRES12_DONT_KNOW',\n",
    "    'PRES16_CLINTON', 'PRES16_TRUMP', 'PRES16_OTHER', 'PRES16_DIDNT_VOTE', 'PRES16_DONT_KNOW',\n",
    "    'PRES20_BIDEN', 'PRES20_TRUMP', 'PRES20_OTHER', 'PRES20_DIDNT_VOTE', 'PRES20_DONT_KNOW',\n",
    "    'IF68WHO_HUMPHREY', 'IF68WHO_NIXON', 'IF68WHO_WALLACE', 'IF68WHO_OTHER', 'IF68WHO_WLDNT_VT_RELIG', 'IF68WHO_DONT_KNOW',\n",
    "    'IF72WHO_MCGOVERN', 'IF72WHO_NIXON', 'IF72WHO_OTHER', 'IF72WHO_REFUSED', 'IF72WHO_WOULDNT_VOTE', 'IF72WHO_WLDNT_VT_RELIG', 'IF72WHO_DONT_KNOW',\n",
    "    'IF76WHO_CARTER', 'IF76WHO_FORD', 'IF76WHO_OTHER', 'IF76WHO_REFUSED', 'IF76WHO_WOULDNT_VOTE', 'IF76WHO_DONT_KNOW',\n",
    "    'IF80WHO_CARTER', 'IF80WHO_REAGAN', 'IF80WHO_ANDERSON', 'IF80WHO_OTHER', 'IF80WHO_WOULDNT_VOTE', 'IF80WHO_REFUSED', 'IF80WHO_DONT_KNOW',\n",
    "    'IF84WHO_MONDALE', 'IF84WHO_REAGAN', 'IF84WHO_OTHER', 'IF84WHO_WOULDNT_VOTE', 'IF84WHO_DONT_KNOW',\n",
    "    'IF88WHO_DUKAKIS', 'IF88WHO_BUSH', 'IF88WHO_OTHER', 'IF88WHO_DONT_KNOW',\n",
    "    'IF92WHO_CLINTON', 'IF92WHO_BUSH', 'IF92WHO_PEROT', 'IF92WHO_OTHER', 'IF92WHO_DONT_KNOW',\n",
    "    'IF96WHO_CLINTON', 'IF96WHO_DOLE', 'IF96WHO_PEROT', 'IF96WHO_OTHER', 'IF96WHO_DONT_KNOW',\n",
    "    'IF00WHO_GORE', 'IF00WHO_BUSH', 'IF00WHO_NADER', 'IF00WHO_OTHER', 'IF00WHO_DONT_KNOW',\n",
    "    'IF04WHO_KERRY', 'IF04WHO_BUSH', 'IF04WHO_NADER', 'IF04WHO_DONT_KNOW',\n",
    "    'IF08WHO_OBAMA', 'IF08WHO_MCCAIN', 'IF08WHO_OTHER', 'IF08WHO_DONT_KNOW',\n",
    "    'IF12WHO_OBAMA', 'IF12WHO_ROMNEY', 'IF12WHO_OTHER', 'IF12WHO_DONT_KNOW',\n",
    "    'IF16WHO_CLINTON', 'IF16WHO_TRUMP', 'IF16WHO_OTHER', 'IF16WHO_CANT_REMEMBER', 'IF16WHO_DONT_KNOW',\n",
    "    'IF20WHO_BIDEN', 'IF20WHO_TRUMP', 'IF20WHO_OTHER', 'IF20WHO_CANT_REMEMBER', 'IF20WHO_DONT_KNOW'\n",
    "]\n",
    "\n",
    "\n",
    "# BROKEN_VARS = [\"RELIG\",'RACOPEN', 'HELPNOT', 'HELPBLK']\n",
    "# Ommited from this list: \"YEAR\", \"BALLOT\", and \"LETDIE1\" (this one sucks!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_belief_network import make_belief_network\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "variables_of_interest = vars_to_use\n",
    "\n",
    "years = [2000, 2002, 2004, 2006, 2008, 2010, 2012]\n",
    "thresholds = [0, 0.2, 0.3, 0.5, 0.6, 0.7]\n",
    "\n",
    "outputs = {year: {partial: {} for partial in [True, False]} for year in years}\n",
    "\n",
    "for year in [2000, 2002, 2004, 2006, 2008, 2010, 2012]:\n",
    "    for partial in [True, False]:\n",
    "        for threshold in thresholds:\n",
    "            BN, variables_list, correlation_matrix = make_belief_network(df, variables_of_interest, [year], method=\"spearman\", is_partial=partial, \n",
    "                                                                threshold=None, sample_threshold=threshold)\n",
    "\n",
    "            outputs[year][partial][threshold] = {\"network\": BN, \"variables\": variables_list, \"corr_mat\": correlation_matrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial = True\n",
    "for year in years:\n",
    "    for threshold in thresholds:\n",
    "        # for partial in [True, False]:\n",
    "            correlation_matrix = outputs[year][partial][threshold][\"corr_mat\"]\n",
    "            BN = outputs[year][partial][threshold][\"network\"]\n",
    "            variables_list = outputs[year][partial][threshold][\"variables\"]\n",
    "\n",
    "            print(f\"{year}, partial corrs: {partial}, threshold: {threshold}\")\n",
    "\n",
    "            correlation_matrix_unique = correlation_matrix[np.triu_indices(correlation_matrix.shape[0], k=1)]\n",
    "\n",
    "            # Print the max and min correlation values\n",
    "            print(f\"Max correlation: {np.max(correlation_matrix_unique)}\")\n",
    "            print(f\"Min correlation: {np.min(correlation_matrix_unique)}\")\n",
    "\n",
    "            # Print num nodes and edges in graph\n",
    "            print(f\"Number of nodes: {len(BN.nodes)}\")\n",
    "            print(f\"Number of edges: {len(BN.edges)}\")\n",
    "        \n",
    "            \"\"\"\n",
    "            # Save the graph as graphml into the folder \"outputs\"\n",
    "            # make the name include the years of interest\n",
    "            years_name = \"_\".join([str(year) for year in years_of_interest])\n",
    "            # filename = f\"{years_name}.graphml\"\n",
    "            filename = \"asdasd.graphml\"\n",
    "            nx.write_graphml(BN, f\"out/{filename}\")\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  # Show all rows without truncation\n",
    "\n",
    "print(df.loc[(df[\"YEAR\"] == 2002) & df[\"CONEDUC\"].isna() & ((df[\"BALLOT\"] == 2.0) | (df[\"BALLOT\"] == 3.0))].notna().any(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_vars, percent_filled, partially_complete = make_variable_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 303)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 303)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_filled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'VOTE72'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\vicvi\\.conda\\envs\\beliefs\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'VOTE72'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nonvoting_percent_filled\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVOTE72\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\vicvi\\.conda\\envs\\beliefs\\Lib\\site-packages\\pandas\\core\\indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\vicvi\\.conda\\envs\\beliefs\\Lib\\site-packages\\pandas\\core\\indexing.py:1368\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1367\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[1;32mc:\\Users\\vicvi\\.conda\\envs\\beliefs\\Lib\\site-packages\\pandas\\core\\indexing.py:1041\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m# we may have a nested tuples indexer here\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_nested_tuple_indexer(tup):\n\u001b[1;32m-> 1041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_nested_tuple(tup)\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# we maybe be using a tuple to represent multiple dimensions here\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m ax0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vicvi\\.conda\\envs\\beliefs\\Lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_nested_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     axis \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m-> 1153\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39m_getitem_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1154\u001b[0m axis \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# if we have a scalar, we are done\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vicvi\\.conda\\envs\\beliefs\\Lib\\site-packages\\pandas\\core\\indexing.py:1431\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_label(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\vicvi\\.conda\\envs\\beliefs\\Lib\\site-packages\\pandas\\core\\indexing.py:1381\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[0;32m   1380\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mxs(label, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\vicvi\\.conda\\envs\\beliefs\\Lib\\site-packages\\pandas\\core\\generic.py:4287\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_level:\n\u001b[1;32m-> 4287\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[0;32m   4288\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\vicvi\\.conda\\envs\\beliefs\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\vicvi\\.conda\\envs\\beliefs\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'VOTE72'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonvoting_percent_filled = percent_filled.drop(PRES_variables, axis=1)\n",
    "nonvoting_percent_filled.to_csv(\"variable_completion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1988.0, 1.0), 'NATENVIR'),\n",
       " ((1988.0, 2.0), 'NATENVIR'),\n",
       " ((1988.0, 3.0), 'NATENVIR'),\n",
       " ((1989.0, 1.0), 'NATENVIR'),\n",
       " ((1989.0, 2.0), 'NATENVIR'),\n",
       " ((1989.0, 3.0), 'NATENVIR'),\n",
       " ((1990.0, 1.0), 'NATENVIR'),\n",
       " ((1990.0, 2.0), 'NATENVIR'),\n",
       " ((1990.0, 3.0), 'NATENVIR'),\n",
       " ((1991.0, 1.0), 'NATENVIR'),\n",
       " ((1991.0, 2.0), 'NATENVIR'),\n",
       " ((1991.0, 3.0), 'NATENVIR'),\n",
       " ((1993.0, 1.0), 'NATENVIR'),\n",
       " ((1993.0, 2.0), 'NATENVIR'),\n",
       " ((1993.0, 3.0), 'NATENVIR'),\n",
       " ((1994.0, 1.0), 'NATENVIR'),\n",
       " ((1994.0, 1.0), 'AFFRMACT'),\n",
       " ((1994.0, 1.0), 'WRKWAYUP'),\n",
       " ((1994.0, 2.0), 'NATENVIR'),\n",
       " ((1994.0, 2.0), 'AFFRMACT'),\n",
       " ((1994.0, 2.0), 'WRKWAYUP'),\n",
       " ((1994.0, 3.0), 'NATENVIR'),\n",
       " ((1996.0, 1.0), 'NATENVIR'),\n",
       " ((1996.0, 2.0), 'NATENVIR'),\n",
       " ((1996.0, 2.0), 'RACOPEN'),\n",
       " ((1996.0, 3.0), 'NATENVIR'),\n",
       " ((1996.0, 3.0), 'RACOPEN'),\n",
       " ((1996.0, 3.0), 'FECHLD'),\n",
       " ((1996.0, 3.0), 'FEPRESCH'),\n",
       " ((1996.0, 3.0), 'FEFAM'),\n",
       " ((1998.0, 1.0), 'NATENVIR'),\n",
       " ((1998.0, 1.0), 'TRUST'),\n",
       " ((1998.0, 2.0), 'NATENVIR'),\n",
       " ((1998.0, 3.0), 'NATENVIR'),\n",
       " ((1998.0, 3.0), 'POSTLIFE'),\n",
       " ((1998.0, 3.0), 'TVHOURS'),\n",
       " ((2000.0, 1.0), 'NATENVIR'),\n",
       " ((2000.0, 2.0), 'NATENVIR'),\n",
       " ((2000.0, 3.0), 'NATENVIR'),\n",
       " ((2000.0, 3.0), 'POSTLIFE'),\n",
       " ((2002.0, 1.0), 'POLVIEWS'),\n",
       " ((2002.0, 1.0), 'NATENVIR'),\n",
       " ((2002.0, 1.0), 'NATSCI'),\n",
       " ((2002.0, 1.0), 'SPKATH'),\n",
       " ((2002.0, 1.0), 'SPKRAC'),\n",
       " ((2002.0, 1.0), 'SPKCOM'),\n",
       " ((2002.0, 1.0), 'SPKMIL'),\n",
       " ((2002.0, 1.0), 'SPKHOMO'),\n",
       " ((2002.0, 1.0), 'COLATH'),\n",
       " ((2002.0, 1.0), 'COLRAC'),\n",
       " ((2002.0, 1.0), 'COLCOM'),\n",
       " ((2002.0, 1.0), 'COLMIL'),\n",
       " ((2002.0, 1.0), 'COLHOMO'),\n",
       " ((2002.0, 1.0), 'LIBATH'),\n",
       " ((2002.0, 1.0), 'LIBRAC'),\n",
       " ((2002.0, 1.0), 'LIBCOM'),\n",
       " ((2002.0, 1.0), 'LIBMIL'),\n",
       " ((2002.0, 1.0), 'LIBHOMO'),\n",
       " ((2002.0, 1.0), 'CAPPUN'),\n",
       " ((2002.0, 1.0), 'GUNLAW'),\n",
       " ((2002.0, 1.0), 'COURTS'),\n",
       " ((2002.0, 1.0), 'POSTLIFE'),\n",
       " ((2002.0, 1.0), 'PRAYER'),\n",
       " ((2002.0, 1.0), 'AFFRMACT'),\n",
       " ((2002.0, 1.0), 'WRKWAYUP'),\n",
       " ((2002.0, 1.0), 'GETAHEAD'),\n",
       " ((2002.0, 1.0), 'FEPOL'),\n",
       " ((2002.0, 1.0), 'ABDEFECT'),\n",
       " ((2002.0, 1.0), 'ABNOMORE'),\n",
       " ((2002.0, 1.0), 'ABHLTH'),\n",
       " ((2002.0, 1.0), 'ABPOOR'),\n",
       " ((2002.0, 1.0), 'ABRAPE'),\n",
       " ((2002.0, 1.0), 'ABSINGLE'),\n",
       " ((2002.0, 1.0), 'ABANY'),\n",
       " ((2002.0, 1.0), 'SEXEDUC'),\n",
       " ((2002.0, 1.0), 'DIVLAW'),\n",
       " ((2002.0, 1.0), 'PREMARSX'),\n",
       " ((2002.0, 1.0), 'TEENSEX'),\n",
       " ((2002.0, 1.0), 'XMARSEX'),\n",
       " ((2002.0, 1.0), 'HOMOSEX'),\n",
       " ((2002.0, 1.0), 'SPANKING'),\n",
       " ((2002.0, 1.0), 'LETDIE1'),\n",
       " ((2002.0, 1.0), 'SUICIDE1'),\n",
       " ((2002.0, 1.0), 'SUICIDE2'),\n",
       " ((2002.0, 1.0), 'NEWS'),\n",
       " ((2002.0, 1.0), 'TVHOURS'),\n",
       " ((2002.0, 1.0), 'FECHLD'),\n",
       " ((2002.0, 1.0), 'FEPRESCH'),\n",
       " ((2002.0, 1.0), 'FEFAM'),\n",
       " ((2002.0, 1.0), 'RACDIF1'),\n",
       " ((2002.0, 1.0), 'RACDIF2'),\n",
       " ((2002.0, 1.0), 'RACDIF3'),\n",
       " ((2002.0, 1.0), 'RACDIF4'),\n",
       " ((2002.0, 2.0), 'POLVIEWS'),\n",
       " ((2002.0, 2.0), 'NATENVIR'),\n",
       " ((2002.0, 2.0), 'NATSCI'),\n",
       " ((2002.0, 2.0), 'EQWLTH'),\n",
       " ((2002.0, 2.0), 'CAPPUN'),\n",
       " ((2002.0, 2.0), 'COURTS'),\n",
       " ((2002.0, 2.0), 'GRASS'),\n",
       " ((2002.0, 2.0), 'POSTLIFE'),\n",
       " ((2002.0, 2.0), 'PRAYER'),\n",
       " ((2002.0, 2.0), 'AFFRMACT'),\n",
       " ((2002.0, 2.0), 'WRKWAYUP'),\n",
       " ((2002.0, 2.0), 'HELPFUL'),\n",
       " ((2002.0, 2.0), 'FAIR'),\n",
       " ((2002.0, 2.0), 'TRUST'),\n",
       " ((2002.0, 2.0), 'CONFINAN'),\n",
       " ((2002.0, 2.0), 'CONBUS'),\n",
       " ((2002.0, 2.0), 'CONCLERG'),\n",
       " ((2002.0, 2.0), 'CONEDUC'),\n",
       " ((2002.0, 2.0), 'CONFED'),\n",
       " ((2002.0, 2.0), 'CONLABOR'),\n",
       " ((2002.0, 2.0), 'CONPRESS'),\n",
       " ((2002.0, 2.0), 'CONMEDIC'),\n",
       " ((2002.0, 2.0), 'CONTV'),\n",
       " ((2002.0, 2.0), 'CONJUDGE'),\n",
       " ((2002.0, 2.0), 'CONSCI'),\n",
       " ((2002.0, 2.0), 'CONLEGIS'),\n",
       " ((2002.0, 2.0), 'CONARMY'),\n",
       " ((2002.0, 2.0), 'OBEY'),\n",
       " ((2002.0, 2.0), 'POPULAR'),\n",
       " ((2002.0, 2.0), 'THNKSELF'),\n",
       " ((2002.0, 2.0), 'WORKHARD'),\n",
       " ((2002.0, 2.0), 'HELPOTH'),\n",
       " ((2002.0, 2.0), 'FEPOL'),\n",
       " ((2002.0, 2.0), 'SEXEDUC'),\n",
       " ((2002.0, 2.0), 'DIVLAW'),\n",
       " ((2002.0, 2.0), 'PREMARSX'),\n",
       " ((2002.0, 2.0), 'TEENSEX'),\n",
       " ((2002.0, 2.0), 'PORNLAW'),\n",
       " ((2002.0, 2.0), 'SPANKING'),\n",
       " ((2002.0, 2.0), 'LETDIE1'),\n",
       " ((2002.0, 2.0), 'SUICIDE1'),\n",
       " ((2002.0, 2.0), 'SUICIDE2'),\n",
       " ((2002.0, 2.0), 'POLHITOK'),\n",
       " ((2002.0, 2.0), 'POLABUSE'),\n",
       " ((2002.0, 2.0), 'POLMURDR'),\n",
       " ((2002.0, 2.0), 'POLESCAP'),\n",
       " ((2002.0, 2.0), 'POLATTAK'),\n",
       " ((2002.0, 2.0), 'NEWS'),\n",
       " ((2002.0, 2.0), 'TVHOURS'),\n",
       " ((2002.0, 2.0), 'FECHLD'),\n",
       " ((2002.0, 2.0), 'FEPRESCH'),\n",
       " ((2002.0, 2.0), 'FEFAM'),\n",
       " ((2002.0, 2.0), 'RACDIF1'),\n",
       " ((2002.0, 2.0), 'RACDIF2'),\n",
       " ((2002.0, 2.0), 'RACDIF3'),\n",
       " ((2002.0, 2.0), 'RACDIF4'),\n",
       " ((2002.0, 2.0), 'HELPPOOR'),\n",
       " ((2002.0, 2.0), 'HELPNOT'),\n",
       " ((2002.0, 2.0), 'HELPBLK'),\n",
       " ((2002.0, 3.0), 'POLVIEWS'),\n",
       " ((2002.0, 3.0), 'NATENVIR'),\n",
       " ((2002.0, 3.0), 'NATSCI'),\n",
       " ((2002.0, 3.0), 'EQWLTH'),\n",
       " ((2002.0, 3.0), 'SPKATH'),\n",
       " ((2002.0, 3.0), 'SPKRAC'),\n",
       " ((2002.0, 3.0), 'SPKCOM'),\n",
       " ((2002.0, 3.0), 'SPKMIL'),\n",
       " ((2002.0, 3.0), 'SPKHOMO'),\n",
       " ((2002.0, 3.0), 'COLATH'),\n",
       " ((2002.0, 3.0), 'COLRAC'),\n",
       " ((2002.0, 3.0), 'COLCOM'),\n",
       " ((2002.0, 3.0), 'COLMIL'),\n",
       " ((2002.0, 3.0), 'COLHOMO'),\n",
       " ((2002.0, 3.0), 'LIBATH'),\n",
       " ((2002.0, 3.0), 'LIBRAC'),\n",
       " ((2002.0, 3.0), 'LIBCOM'),\n",
       " ((2002.0, 3.0), 'LIBMIL'),\n",
       " ((2002.0, 3.0), 'LIBHOMO'),\n",
       " ((2002.0, 3.0), 'CAPPUN'),\n",
       " ((2002.0, 3.0), 'GUNLAW'),\n",
       " ((2002.0, 3.0), 'COURTS'),\n",
       " ((2002.0, 3.0), 'GRASS'),\n",
       " ((2002.0, 3.0), 'POSTLIFE'),\n",
       " ((2002.0, 3.0), 'HELPFUL'),\n",
       " ((2002.0, 3.0), 'FAIR'),\n",
       " ((2002.0, 3.0), 'TRUST'),\n",
       " ((2002.0, 3.0), 'CONFINAN'),\n",
       " ((2002.0, 3.0), 'CONBUS'),\n",
       " ((2002.0, 3.0), 'CONCLERG'),\n",
       " ((2002.0, 3.0), 'CONEDUC'),\n",
       " ((2002.0, 3.0), 'CONFED'),\n",
       " ((2002.0, 3.0), 'CONLABOR'),\n",
       " ((2002.0, 3.0), 'CONPRESS'),\n",
       " ((2002.0, 3.0), 'CONMEDIC'),\n",
       " ((2002.0, 3.0), 'CONTV'),\n",
       " ((2002.0, 3.0), 'CONJUDGE'),\n",
       " ((2002.0, 3.0), 'CONSCI'),\n",
       " ((2002.0, 3.0), 'CONLEGIS'),\n",
       " ((2002.0, 3.0), 'CONARMY'),\n",
       " ((2002.0, 3.0), 'OBEY'),\n",
       " ((2002.0, 3.0), 'POPULAR'),\n",
       " ((2002.0, 3.0), 'THNKSELF'),\n",
       " ((2002.0, 3.0), 'WORKHARD'),\n",
       " ((2002.0, 3.0), 'HELPOTH'),\n",
       " ((2002.0, 3.0), 'GETAHEAD'),\n",
       " ((2002.0, 3.0), 'ABDEFECT'),\n",
       " ((2002.0, 3.0), 'ABNOMORE'),\n",
       " ((2002.0, 3.0), 'ABHLTH'),\n",
       " ((2002.0, 3.0), 'ABPOOR'),\n",
       " ((2002.0, 3.0), 'ABRAPE'),\n",
       " ((2002.0, 3.0), 'ABSINGLE'),\n",
       " ((2002.0, 3.0), 'ABANY'),\n",
       " ((2002.0, 3.0), 'XMARSEX'),\n",
       " ((2002.0, 3.0), 'HOMOSEX'),\n",
       " ((2002.0, 3.0), 'PORNLAW'),\n",
       " ((2002.0, 3.0), 'POLHITOK'),\n",
       " ((2002.0, 3.0), 'POLABUSE'),\n",
       " ((2002.0, 3.0), 'POLMURDR'),\n",
       " ((2002.0, 3.0), 'POLESCAP'),\n",
       " ((2002.0, 3.0), 'POLATTAK'),\n",
       " ((2002.0, 3.0), 'HELPPOOR'),\n",
       " ((2002.0, 3.0), 'HELPNOT'),\n",
       " ((2002.0, 3.0), 'HELPBLK'),\n",
       " ((2004.0, 1.0), 'POLVIEWS'),\n",
       " ((2004.0, 1.0), 'NATENVIR'),\n",
       " ((2004.0, 1.0), 'NATSCI'),\n",
       " ((2004.0, 1.0), 'SPKATH'),\n",
       " ((2004.0, 1.0), 'SPKRAC'),\n",
       " ((2004.0, 1.0), 'SPKCOM'),\n",
       " ((2004.0, 1.0), 'SPKMIL'),\n",
       " ((2004.0, 1.0), 'SPKHOMO'),\n",
       " ((2004.0, 1.0), 'COLATH'),\n",
       " ((2004.0, 1.0), 'COLRAC'),\n",
       " ((2004.0, 1.0), 'COLCOM'),\n",
       " ((2004.0, 1.0), 'COLMIL'),\n",
       " ((2004.0, 1.0), 'COLHOMO'),\n",
       " ((2004.0, 1.0), 'LIBATH'),\n",
       " ((2004.0, 1.0), 'LIBRAC'),\n",
       " ((2004.0, 1.0), 'LIBCOM'),\n",
       " ((2004.0, 1.0), 'LIBMIL'),\n",
       " ((2004.0, 1.0), 'LIBHOMO'),\n",
       " ((2004.0, 1.0), 'CAPPUN'),\n",
       " ((2004.0, 1.0), 'GUNLAW'),\n",
       " ((2004.0, 1.0), 'COURTS'),\n",
       " ((2004.0, 1.0), 'POSTLIFE'),\n",
       " ((2004.0, 1.0), 'PRAYER'),\n",
       " ((2004.0, 1.0), 'RACOPEN'),\n",
       " ((2004.0, 1.0), 'AFFRMACT'),\n",
       " ((2004.0, 1.0), 'WRKWAYUP'),\n",
       " ((2004.0, 1.0), 'GETAHEAD'),\n",
       " ((2004.0, 1.0), 'FEPOL'),\n",
       " ((2004.0, 1.0), 'ABDEFECT'),\n",
       " ((2004.0, 1.0), 'ABNOMORE'),\n",
       " ((2004.0, 1.0), 'ABHLTH'),\n",
       " ((2004.0, 1.0), 'ABPOOR'),\n",
       " ((2004.0, 1.0), 'ABRAPE'),\n",
       " ((2004.0, 1.0), 'ABSINGLE'),\n",
       " ((2004.0, 1.0), 'ABANY'),\n",
       " ((2004.0, 1.0), 'SEXEDUC'),\n",
       " ((2004.0, 1.0), 'DIVLAW'),\n",
       " ((2004.0, 1.0), 'PREMARSX'),\n",
       " ((2004.0, 1.0), 'TEENSEX'),\n",
       " ((2004.0, 1.0), 'XMARSEX'),\n",
       " ((2004.0, 1.0), 'HOMOSEX'),\n",
       " ((2004.0, 1.0), 'SPANKING'),\n",
       " ((2004.0, 1.0), 'LETDIE1'),\n",
       " ((2004.0, 1.0), 'SUICIDE1'),\n",
       " ((2004.0, 1.0), 'SUICIDE2'),\n",
       " ((2004.0, 1.0), 'NEWS'),\n",
       " ((2004.0, 1.0), 'TVHOURS'),\n",
       " ((2004.0, 1.0), 'FECHLD'),\n",
       " ((2004.0, 1.0), 'FEPRESCH'),\n",
       " ((2004.0, 1.0), 'FEFAM'),\n",
       " ((2004.0, 1.0), 'RACDIF1'),\n",
       " ((2004.0, 1.0), 'RACDIF2'),\n",
       " ((2004.0, 1.0), 'RACDIF3'),\n",
       " ((2004.0, 1.0), 'RACDIF4'),\n",
       " ((2004.0, 1.0), 'MARHOMO'),\n",
       " ((2004.0, 2.0), 'POLVIEWS'),\n",
       " ((2004.0, 2.0), 'NATENVIR'),\n",
       " ((2004.0, 2.0), 'NATSCI'),\n",
       " ((2004.0, 2.0), 'EQWLTH'),\n",
       " ((2004.0, 2.0), 'CAPPUN'),\n",
       " ((2004.0, 2.0), 'COURTS'),\n",
       " ((2004.0, 2.0), 'GRASS'),\n",
       " ((2004.0, 2.0), 'POSTLIFE'),\n",
       " ((2004.0, 2.0), 'PRAYER'),\n",
       " ((2004.0, 2.0), 'AFFRMACT'),\n",
       " ((2004.0, 2.0), 'WRKWAYUP'),\n",
       " ((2004.0, 2.0), 'HELPFUL'),\n",
       " ((2004.0, 2.0), 'FAIR'),\n",
       " ((2004.0, 2.0), 'TRUST'),\n",
       " ((2004.0, 2.0), 'CONFINAN'),\n",
       " ((2004.0, 2.0), 'CONBUS'),\n",
       " ((2004.0, 2.0), 'CONCLERG'),\n",
       " ((2004.0, 2.0), 'CONEDUC'),\n",
       " ((2004.0, 2.0), 'CONFED'),\n",
       " ((2004.0, 2.0), 'CONLABOR'),\n",
       " ((2004.0, 2.0), 'CONPRESS'),\n",
       " ((2004.0, 2.0), 'CONMEDIC'),\n",
       " ((2004.0, 2.0), 'CONTV'),\n",
       " ((2004.0, 2.0), 'CONJUDGE'),\n",
       " ((2004.0, 2.0), 'CONSCI'),\n",
       " ((2004.0, 2.0), 'CONLEGIS'),\n",
       " ((2004.0, 2.0), 'CONARMY'),\n",
       " ((2004.0, 2.0), 'OBEY'),\n",
       " ((2004.0, 2.0), 'POPULAR'),\n",
       " ((2004.0, 2.0), 'THNKSELF'),\n",
       " ((2004.0, 2.0), 'WORKHARD'),\n",
       " ((2004.0, 2.0), 'HELPOTH'),\n",
       " ((2004.0, 2.0), 'FEPOL'),\n",
       " ((2004.0, 2.0), 'SEXEDUC'),\n",
       " ((2004.0, 2.0), 'DIVLAW'),\n",
       " ((2004.0, 2.0), 'PREMARSX'),\n",
       " ((2004.0, 2.0), 'TEENSEX'),\n",
       " ((2004.0, 2.0), 'PORNLAW'),\n",
       " ((2004.0, 2.0), 'SPANKING'),\n",
       " ((2004.0, 2.0), 'LETDIE1'),\n",
       " ((2004.0, 2.0), 'SUICIDE1'),\n",
       " ((2004.0, 2.0), 'SUICIDE2'),\n",
       " ((2004.0, 2.0), 'POLHITOK'),\n",
       " ((2004.0, 2.0), 'POLABUSE'),\n",
       " ((2004.0, 2.0), 'POLMURDR'),\n",
       " ((2004.0, 2.0), 'POLESCAP'),\n",
       " ((2004.0, 2.0), 'POLATTAK'),\n",
       " ((2004.0, 2.0), 'NEWS'),\n",
       " ((2004.0, 2.0), 'TVHOURS'),\n",
       " ((2004.0, 2.0), 'FECHLD'),\n",
       " ((2004.0, 2.0), 'FEPRESCH'),\n",
       " ((2004.0, 2.0), 'FEFAM'),\n",
       " ((2004.0, 2.0), 'RACDIF1'),\n",
       " ((2004.0, 2.0), 'RACDIF2'),\n",
       " ((2004.0, 2.0), 'RACDIF3'),\n",
       " ((2004.0, 2.0), 'RACDIF4'),\n",
       " ((2004.0, 2.0), 'HELPPOOR'),\n",
       " ((2004.0, 2.0), 'HELPNOT'),\n",
       " ((2004.0, 2.0), 'HELPBLK'),\n",
       " ((2004.0, 2.0), 'MARHOMO'),\n",
       " ((2004.0, 3.0), 'POLVIEWS'),\n",
       " ((2004.0, 3.0), 'NATENVIR'),\n",
       " ((2004.0, 3.0), 'NATSCI'),\n",
       " ((2004.0, 3.0), 'EQWLTH'),\n",
       " ((2004.0, 3.0), 'SPKATH'),\n",
       " ((2004.0, 3.0), 'SPKRAC'),\n",
       " ((2004.0, 3.0), 'SPKCOM'),\n",
       " ((2004.0, 3.0), 'SPKMIL'),\n",
       " ((2004.0, 3.0), 'SPKHOMO'),\n",
       " ((2004.0, 3.0), 'COLATH'),\n",
       " ((2004.0, 3.0), 'COLRAC'),\n",
       " ((2004.0, 3.0), 'COLCOM'),\n",
       " ((2004.0, 3.0), 'COLMIL'),\n",
       " ((2004.0, 3.0), 'COLHOMO'),\n",
       " ((2004.0, 3.0), 'LIBATH'),\n",
       " ((2004.0, 3.0), 'LIBRAC'),\n",
       " ((2004.0, 3.0), 'LIBCOM'),\n",
       " ((2004.0, 3.0), 'LIBMIL'),\n",
       " ((2004.0, 3.0), 'LIBHOMO'),\n",
       " ((2004.0, 3.0), 'CAPPUN'),\n",
       " ((2004.0, 3.0), 'GUNLAW'),\n",
       " ((2004.0, 3.0), 'COURTS'),\n",
       " ((2004.0, 3.0), 'GRASS'),\n",
       " ((2004.0, 3.0), 'POSTLIFE'),\n",
       " ((2004.0, 3.0), 'RACOPEN'),\n",
       " ((2004.0, 3.0), 'HELPFUL'),\n",
       " ((2004.0, 3.0), 'FAIR'),\n",
       " ((2004.0, 3.0), 'TRUST'),\n",
       " ((2004.0, 3.0), 'CONFINAN'),\n",
       " ((2004.0, 3.0), 'CONBUS'),\n",
       " ((2004.0, 3.0), 'CONCLERG'),\n",
       " ((2004.0, 3.0), 'CONEDUC'),\n",
       " ((2004.0, 3.0), 'CONFED'),\n",
       " ((2004.0, 3.0), 'CONLABOR'),\n",
       " ((2004.0, 3.0), 'CONPRESS'),\n",
       " ((2004.0, 3.0), 'CONMEDIC'),\n",
       " ((2004.0, 3.0), 'CONTV'),\n",
       " ((2004.0, 3.0), 'CONJUDGE'),\n",
       " ((2004.0, 3.0), 'CONSCI'),\n",
       " ((2004.0, 3.0), 'CONLEGIS'),\n",
       " ((2004.0, 3.0), 'CONARMY'),\n",
       " ((2004.0, 3.0), 'OBEY'),\n",
       " ((2004.0, 3.0), 'POPULAR'),\n",
       " ((2004.0, 3.0), 'THNKSELF'),\n",
       " ((2004.0, 3.0), 'WORKHARD'),\n",
       " ((2004.0, 3.0), 'HELPOTH'),\n",
       " ((2004.0, 3.0), 'GETAHEAD'),\n",
       " ((2004.0, 3.0), 'ABDEFECT'),\n",
       " ((2004.0, 3.0), 'ABNOMORE'),\n",
       " ((2004.0, 3.0), 'ABHLTH'),\n",
       " ((2004.0, 3.0), 'ABPOOR'),\n",
       " ((2004.0, 3.0), 'ABRAPE'),\n",
       " ((2004.0, 3.0), 'ABSINGLE'),\n",
       " ((2004.0, 3.0), 'ABANY'),\n",
       " ((2004.0, 3.0), 'XMARSEX'),\n",
       " ((2004.0, 3.0), 'HOMOSEX'),\n",
       " ((2004.0, 3.0), 'PORNLAW'),\n",
       " ((2004.0, 3.0), 'POLHITOK'),\n",
       " ((2004.0, 3.0), 'POLABUSE'),\n",
       " ((2004.0, 3.0), 'POLMURDR'),\n",
       " ((2004.0, 3.0), 'POLESCAP'),\n",
       " ((2004.0, 3.0), 'POLATTAK'),\n",
       " ((2004.0, 3.0), 'HELPPOOR'),\n",
       " ((2004.0, 3.0), 'HELPNOT'),\n",
       " ((2004.0, 3.0), 'HELPBLK'),\n",
       " ((2004.0, 3.0), 'MARHOMO'),\n",
       " ((2006.0, 1.0), 'NATENVIR'),\n",
       " ((2006.0, 1.0), 'TRUST'),\n",
       " ((2006.0, 2.0), 'NATENVIR'),\n",
       " ((2006.0, 2.0), 'OBEY'),\n",
       " ((2006.0, 2.0), 'POPULAR'),\n",
       " ((2006.0, 2.0), 'THNKSELF'),\n",
       " ((2006.0, 2.0), 'WORKHARD'),\n",
       " ((2006.0, 2.0), 'HELPOTH'),\n",
       " ((2006.0, 3.0), 'NATENVIR'),\n",
       " ((2006.0, 3.0), 'OBEY'),\n",
       " ((2006.0, 3.0), 'POPULAR'),\n",
       " ((2006.0, 3.0), 'THNKSELF'),\n",
       " ((2006.0, 3.0), 'WORKHARD'),\n",
       " ((2006.0, 3.0), 'HELPOTH'),\n",
       " ((2006.0, 4.0), 'GETAHEAD'),\n",
       " ((2006.0, 4.0), 'NEWS'),\n",
       " ((2008.0, 1.0), 'NATENVIR'),\n",
       " ((2008.0, 1.0), 'LETDIE1'),\n",
       " ((2008.0, 2.0), 'NATENVIR'),\n",
       " ((2008.0, 2.0), 'LETDIE1'),\n",
       " ((2008.0, 2.0), 'POLHITOK'),\n",
       " ((2008.0, 3.0), 'NATENVIR'),\n",
       " ((2008.0, 3.0), 'POLHITOK'),\n",
       " ((2010.0, 1.0), 'NATENVIR'),\n",
       " ((2010.0, 2.0), 'NATENVIR'),\n",
       " ((2010.0, 3.0), 'NATENVIR'),\n",
       " ((2012.0, 1.0), 'NATENVIR'),\n",
       " ((2012.0, 2.0), 'NATENVIR'),\n",
       " ((2012.0, 3.0), 'NATENVIR'),\n",
       " ((2014.0, 1.0), 'NATENVIR'),\n",
       " ((2014.0, 2.0), 'NATENVIR'),\n",
       " ((2014.0, 3.0), 'NATENVIR'),\n",
       " ((2016.0, 1.0), 'NATENVIR'),\n",
       " ((2016.0, 2.0), 'NATENVIR'),\n",
       " ((2016.0, 3.0), 'NATENVIR'),\n",
       " ((2018.0, 1.0), 'NATENVIR'),\n",
       " ((2018.0, 2.0), 'NATENVIR'),\n",
       " ((2018.0, 3.0), 'NATENVIR'),\n",
       " ((2021.0, 1.0), 'NATENVIR'),\n",
       " ((2021.0, 1.0), 'SPKATH'),\n",
       " ((2021.0, 1.0), 'SPKRAC'),\n",
       " ((2021.0, 1.0), 'SPKCOM'),\n",
       " ((2021.0, 1.0), 'SPKMIL'),\n",
       " ((2021.0, 1.0), 'SPKHOMO'),\n",
       " ((2021.0, 1.0), 'SPKMSLM'),\n",
       " ((2021.0, 1.0), 'COLCOM'),\n",
       " ((2021.0, 1.0), 'LIBATH'),\n",
       " ((2021.0, 1.0), 'LIBRAC'),\n",
       " ((2021.0, 1.0), 'LIBCOM'),\n",
       " ((2021.0, 1.0), 'LIBMIL'),\n",
       " ((2021.0, 1.0), 'LIBHOMO'),\n",
       " ((2021.0, 1.0), 'LIBMSLM'),\n",
       " ((2021.0, 1.0), 'ABDEFECT'),\n",
       " ((2021.0, 1.0), 'ABNOMORE'),\n",
       " ((2021.0, 1.0), 'ABHLTH'),\n",
       " ((2021.0, 1.0), 'ABPOOR'),\n",
       " ((2021.0, 1.0), 'ABRAPE'),\n",
       " ((2021.0, 1.0), 'ABSINGLE'),\n",
       " ((2021.0, 1.0), 'ABANY'),\n",
       " ((2021.0, 1.0), 'LETDIE1'),\n",
       " ((2021.0, 1.0), 'SUICIDE1'),\n",
       " ((2021.0, 1.0), 'SUICIDE2'),\n",
       " ((2021.0, 2.0), 'NATENVIR'),\n",
       " ((2021.0, 2.0), 'LETDIE1'),\n",
       " ((2021.0, 2.0), 'SUICIDE1'),\n",
       " ((2021.0, 2.0), 'SUICIDE2'),\n",
       " ((2021.0, 2.0), 'POLHITOK'),\n",
       " ((2021.0, 2.0), 'POLABUSE'),\n",
       " ((2021.0, 2.0), 'POLATTAK'),\n",
       " ((2021.0, 3.0), 'NATENVIR'),\n",
       " ((2021.0, 3.0), 'SPKATH'),\n",
       " ((2021.0, 3.0), 'SPKRAC'),\n",
       " ((2021.0, 3.0), 'SPKCOM'),\n",
       " ((2021.0, 3.0), 'SPKMIL'),\n",
       " ((2021.0, 3.0), 'SPKHOMO'),\n",
       " ((2021.0, 3.0), 'SPKMSLM'),\n",
       " ((2021.0, 3.0), 'COLCOM'),\n",
       " ((2021.0, 3.0), 'LIBATH'),\n",
       " ((2021.0, 3.0), 'LIBRAC'),\n",
       " ((2021.0, 3.0), 'LIBCOM'),\n",
       " ((2021.0, 3.0), 'LIBMIL'),\n",
       " ((2021.0, 3.0), 'LIBHOMO'),\n",
       " ((2021.0, 3.0), 'LIBMSLM'),\n",
       " ((2021.0, 3.0), 'ABDEFECT'),\n",
       " ((2021.0, 3.0), 'ABNOMORE'),\n",
       " ((2021.0, 3.0), 'ABHLTH'),\n",
       " ((2021.0, 3.0), 'ABPOOR'),\n",
       " ((2021.0, 3.0), 'ABRAPE'),\n",
       " ((2021.0, 3.0), 'ABSINGLE'),\n",
       " ((2021.0, 3.0), 'ABANY'),\n",
       " ((2021.0, 3.0), 'POLHITOK'),\n",
       " ((2021.0, 3.0), 'POLABUSE'),\n",
       " ((2021.0, 3.0), 'POLATTAK'),\n",
       " ((2022.0, 1.0), 'NATENVIR'),\n",
       " ((2022.0, 1.0), 'SPKATH'),\n",
       " ((2022.0, 1.0), 'SPKRAC'),\n",
       " ((2022.0, 1.0), 'SPKCOM'),\n",
       " ((2022.0, 1.0), 'SPKMSLM'),\n",
       " ((2022.0, 1.0), 'COLCOM'),\n",
       " ((2022.0, 1.0), 'LIBATH'),\n",
       " ((2022.0, 1.0), 'LIBRAC'),\n",
       " ((2022.0, 1.0), 'LIBCOM'),\n",
       " ((2022.0, 1.0), 'LIBMSLM'),\n",
       " ((2022.0, 1.0), 'COURTS'),\n",
       " ((2022.0, 1.0), 'RELITEN'),\n",
       " ((2022.0, 1.0), 'POSTLIFE'),\n",
       " ((2022.0, 1.0), 'PRAYER'),\n",
       " ((2022.0, 1.0), 'RACOPEN'),\n",
       " ((2022.0, 1.0), 'GETAHEAD'),\n",
       " ((2022.0, 1.0), 'FEPOL'),\n",
       " ((2022.0, 1.0), 'ABDEFECT'),\n",
       " ((2022.0, 1.0), 'ABNOMORE'),\n",
       " ((2022.0, 1.0), 'ABHLTH'),\n",
       " ((2022.0, 1.0), 'ABPOOR'),\n",
       " ((2022.0, 1.0), 'ABRAPE'),\n",
       " ((2022.0, 1.0), 'ABSINGLE'),\n",
       " ((2022.0, 1.0), 'ABANY'),\n",
       " ((2022.0, 1.0), 'DIVLAW'),\n",
       " ((2022.0, 1.0), 'LETDIE1'),\n",
       " ((2022.0, 1.0), 'SUICIDE1'),\n",
       " ((2022.0, 1.0), 'SUICIDE2'),\n",
       " ((2022.0, 1.0), 'RACDIF1'),\n",
       " ((2022.0, 1.0), 'RACDIF2'),\n",
       " ((2022.0, 1.0), 'RACDIF3'),\n",
       " ((2022.0, 1.0), 'RACDIF4'),\n",
       " ((2022.0, 2.0), 'NATENVIR'),\n",
       " ((2022.0, 2.0), 'COURTS'),\n",
       " ((2022.0, 2.0), 'GRASS'),\n",
       " ((2022.0, 2.0), 'RELITEN'),\n",
       " ((2022.0, 2.0), 'POSTLIFE'),\n",
       " ((2022.0, 2.0), 'PRAYER'),\n",
       " ((2022.0, 2.0), 'HELPFUL'),\n",
       " ((2022.0, 2.0), 'FAIR'),\n",
       " ((2022.0, 2.0), 'TRUST'),\n",
       " ((2022.0, 2.0), 'FEPOL'),\n",
       " ((2022.0, 2.0), 'DIVLAW'),\n",
       " ((2022.0, 2.0), 'LETDIE1'),\n",
       " ((2022.0, 2.0), 'SUICIDE1'),\n",
       " ((2022.0, 2.0), 'SUICIDE2'),\n",
       " ((2022.0, 2.0), 'POLHITOK'),\n",
       " ((2022.0, 2.0), 'POLABUSE'),\n",
       " ((2022.0, 2.0), 'POLATTAK'),\n",
       " ((2022.0, 2.0), 'RACDIF1'),\n",
       " ((2022.0, 2.0), 'RACDIF2'),\n",
       " ((2022.0, 2.0), 'RACDIF3'),\n",
       " ((2022.0, 2.0), 'RACDIF4'),\n",
       " ((2022.0, 3.0), 'NATENVIR'),\n",
       " ((2022.0, 3.0), 'SPKATH'),\n",
       " ((2022.0, 3.0), 'SPKRAC'),\n",
       " ((2022.0, 3.0), 'SPKCOM'),\n",
       " ((2022.0, 3.0), 'SPKMSLM'),\n",
       " ((2022.0, 3.0), 'COLCOM'),\n",
       " ((2022.0, 3.0), 'LIBATH'),\n",
       " ((2022.0, 3.0), 'LIBRAC'),\n",
       " ((2022.0, 3.0), 'LIBCOM'),\n",
       " ((2022.0, 3.0), 'LIBMSLM'),\n",
       " ((2022.0, 3.0), 'COURTS'),\n",
       " ((2022.0, 3.0), 'GRASS'),\n",
       " ((2022.0, 3.0), 'RELITEN'),\n",
       " ((2022.0, 3.0), 'POSTLIFE'),\n",
       " ((2022.0, 3.0), 'RACOPEN'),\n",
       " ((2022.0, 3.0), 'HELPFUL'),\n",
       " ((2022.0, 3.0), 'FAIR'),\n",
       " ((2022.0, 3.0), 'TRUST'),\n",
       " ((2022.0, 3.0), 'GETAHEAD'),\n",
       " ((2022.0, 3.0), 'ABDEFECT'),\n",
       " ((2022.0, 3.0), 'ABNOMORE'),\n",
       " ((2022.0, 3.0), 'ABHLTH'),\n",
       " ((2022.0, 3.0), 'ABPOOR'),\n",
       " ((2022.0, 3.0), 'ABRAPE'),\n",
       " ((2022.0, 3.0), 'ABSINGLE'),\n",
       " ((2022.0, 3.0), 'ABANY'),\n",
       " ((2022.0, 3.0), 'POLHITOK'),\n",
       " ((2022.0, 3.0), 'POLABUSE'),\n",
       " ((2022.0, 3.0), 'POLATTAK')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[coord for coord in partially_complete if coord[1] not in PRES_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'A': [1.0, np.nan, 3.0, 4.0],\n",
    "    'B': [5.0, 6.0, np.nan, 8.0],\n",
    "    'C': [np.nan, 10.0, 11.0, 12.0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A      B      C\n",
       "0   True   True  False\n",
       "1  False   True   True\n",
       "2   True  False   True\n",
       "3   True   True   True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partially_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_in_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "def find_triads(G, threshhold=0):\n",
    "    nodes = G.nodes()\n",
    "    triads = list(combinations(nodes, 3))\n",
    "    positive_triads = []\n",
    "    negative_triads = []\n",
    "\n",
    "    for triad in triads:\n",
    "        edges = [(triad[0], triad[1]), (triad[1], triad[2]), (triad[0], triad[2])]\n",
    "        weights = [G[u][v]['weight'] for u, v in edges if G.has_edge(u, v)]\n",
    "\n",
    "        # Ensure all edges exist, otherwise skip\n",
    "        if len(weights) == 3:\n",
    "            if abs(weights[0]) > threshhold and abs(weights[1]) > threshhold and abs(weights[2]) > threshhold:\n",
    "            \n",
    "                product = weights[0] * weights[1] * weights[2]\n",
    "                if product > 0:\n",
    "                    positive_triads.append(triad)\n",
    "                elif product < 0:\n",
    "                    negative_triads.append(triad)\n",
    "\n",
    "    return positive_triads, negative_triads\n",
    "\n",
    "# Create graph and find the triads, and print the number of triads\n",
    "G = BN\n",
    "positive_triads, negative_triads = find_triads(G, threshhold=0.2)\n",
    "print(f\"Number of balanced triads: {len(positive_triads)}\")\n",
    "print(f\"Number of unbalanced triads: {len(negative_triads)}\")\n",
    "\n",
    "# Print the triads\n",
    "print(\"Balanced triads:\", positive_triads)\n",
    "print(\"Unbalanced triads:\", negative_triads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the histogram of the correlation matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(correlation_matrix.flatten(), bins=100)\n",
    "plt.xlabel(\"Correlation coefficient\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of correlation coefficients\")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50, 0: negatives: 0.9085612244897957, positives: 0.09143877551020407\n",
      "50, 0.1: negatives: 0.4066961724541849, positives: 0.593303827545815\n",
      "50, 0.2: negatives: 0.1466443268449485, positives: 0.8533556731550516\n",
      "100, 0: negatives: 0.8615231910946198, positives: 0.13847680890538033\n",
      "100, 0.1: negatives: 0.3687557270077323, positives: 0.6312442729922675\n",
      "100, 0.2: negatives: 0.06392224461303408, positives: 0.9360777553869658\n",
      "200, 0: negatives: 0.8667048119384804, positives: 0.13329518806151974\n",
      "200, 0.1: negatives: 0.30971363922537154, positives: 0.6902863607746283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:30: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  neg_counts.append(negative_count / (negative_count + positive_count))\n",
      "C:\\Users\\vicvi\\AppData\\Local\\Temp\\ipykernel_23160\\3102570745.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  pos_counts.append(positive_count / (negative_count + positive_count))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200, 0.2: negatives: nan, positives: nan\n"
     ]
    }
   ],
   "source": [
    "measurements = {dim: {alpha: {} for alpha in [0, 0.1, 0.2]} for dim in [50, 100, 200]}\n",
    "for dim in [50, 100, 200]:\n",
    "    for alpha in [0, 0.1, 0.2]:\n",
    "        neg_counts = []\n",
    "        pos_counts = []\n",
    "        for i in range(20):\n",
    "            random_matrix = random_mat = 2 * np.random.rand(dim, dim) - 1\n",
    "            random_cov_mat = np.dot(random_matrix, random_matrix.T)\n",
    "\n",
    "            std_deviations = np.sqrt(np.diag(random_cov_mat))\n",
    "            random_corr_mat = random_cov_mat / np.outer(std_deviations, std_deviations)\n",
    "\n",
    "            random_partial_corr_mat = cov_mat_to_regularized_partial_corr(random_corr_mat, alpha=alpha)\n",
    "\n",
    "            positive_count, negative_count = count_triads(ra)\n",
    "            \n",
    "            neg_counts.append(negative_count / (negative_count + positive_count))\n",
    "            pos_counts.append(positive_count / (negative_count + positive_count))\n",
    "        \n",
    "        print(f\"{dim}, {alpha}: negatives: {sum(neg_counts) / len(neg_counts)}, positives: {sum(pos_counts) / len(pos_counts)}\")\n",
    "        measurements[dim][alpha][\"neg\"] = sum(neg_counts) / len(neg_counts)\n",
    "        measurements[dim][alpha][\"pos\"] =  sum(pos_counts) / len(pos_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VOTE68</th>\n",
       "      <th>VOTE72</th>\n",
       "      <th>VOTE76</th>\n",
       "      <th>VOTE80</th>\n",
       "      <th>PRES68</th>\n",
       "      <th>PRES72</th>\n",
       "      <th>PRES76</th>\n",
       "      <th>PRES80</th>\n",
       "      <th>VOTELAST</th>\n",
       "      <th>PRESLAST</th>\n",
       "      <th>VOTELASTEXP</th>\n",
       "      <th>PRESLASTEXP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>-4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>-4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VOTE68  VOTE72  VOTE76  VOTE80  PRES68  PRES72  PRES76  PRES80  VOTELAST  \\\n",
       "0     1.0     NaN     NaN     NaN    -1.0     NaN     NaN     NaN       1.0   \n",
       "1     1.1     2.0     NaN     NaN    -1.1    -2.0     NaN     NaN       2.0   \n",
       "2     1.2     2.1     3.0     NaN    -1.2    -2.1    -3.0     NaN       3.0   \n",
       "3     1.3     2.2     3.1     4.0    -1.3    -2.2    -3.1    -4.0       4.0   \n",
       "4     NaN     2.3     3.2     4.1     NaN    -2.3    -3.2    -4.1       4.1   \n",
       "5     NaN     NaN     3.3     4.2     NaN     NaN    -3.3    -4.2       4.2   \n",
       "6     NaN     NaN     NaN     4.3     NaN     NaN     NaN    -4.3       4.3   \n",
       "7     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN       NaN   \n",
       "\n",
       "   PRESLAST  VOTELASTEXP  PRESLASTEXP  \n",
       "0      -1.0          1.0         -1.0  \n",
       "1      -2.0          2.0         -2.0  \n",
       "2      -3.0          3.0         -3.0  \n",
       "3      -4.0          4.0         -4.0  \n",
       "4      -4.1          4.1         -4.1  \n",
       "5      -4.2          4.2         -4.2  \n",
       "6      -4.3          4.3         -4.3  \n",
       "7       NaN          NaN          NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faithful_df = pd.DataFrame({\n",
    "    \"VOTE68\": [   1.0,    1.1,    1.2,    1.3, np.nan, np.nan, np.nan, np.nan],\n",
    "    \"VOTE72\": [np.nan,    2.0,    2.1,    2.2,    2.3, np.nan, np.nan, np.nan],\n",
    "    \"VOTE76\": [np.nan, np.nan,    3.0,    3.1,    3.2,    3.3, np.nan, np.nan],\n",
    "    \"VOTE80\": [np.nan, np.nan, np.nan,    4.0,    4.1,    4.2,    4.3, np.nan],\n",
    "    \"PRES68\": [  -1.0,   -1.1,   -1.2,   -1.3, np.nan, np.nan, np.nan, np.nan],\n",
    "    \"PRES72\": [np.nan,   -2.0,   -2.1,   -2.2,   -2.3, np.nan, np.nan, np.nan],\n",
    "    \"PRES76\": [np.nan, np.nan,   -3.0,   -3.1,   -3.2,   -3.3, np.nan, np.nan], \n",
    "    \"PRES80\": [np.nan, np.nan, np.nan,   -4.0,   -4.1,   -4.2,   -4.3, np.nan] \n",
    "})\n",
    "vote_faithful_exp = [1.0, 2.0, 3.0, 4.0, 4.1, 4.2, 4.3, np.nan]\n",
    "pres_faithful_exp = [-1.0, -2.0, -3.0, -4.0, -4.1, -4.2, -4.3, np.nan]\n",
    "\n",
    "weird_df = pd.DataFrame({\n",
    "    \"VOTE68\": [   1.0, np.nan,    1.1, np.nan,    1.2, np.nan,    1.3, np.nan],\n",
    "    \"VOTE72\": [np.nan,    2.0,    2.1, np.nan,    2.2,    2.3, np.nan, np.nan],\n",
    "    \"VOTE76\": [np.nan, np.nan,    3.0,    3.1,    3.2, np.nan, np.nan,    3.3],\n",
    "    \"VOTE80\": [np.nan, np.nan, np.nan,    4.0,    4.1, np.nan, np.nan, np.nan],\n",
    "    \"PRES68\": [  -1.0, np.nan,   -1.1, np.nan,   -1.2, np.nan,   -1.3, np.nan],\n",
    "    \"PRES72\": [np.nan,   -2.0,   -2.1, np.nan,   -2.2,   -2.3, np.nan, np.nan],\n",
    "    \"PRES76\": [np.nan, np.nan,   -3.0,   -3.1,   -3.2, np.nan, np.nan,   -3.3],\n",
    "    \"PRES80\": [np.nan, np.nan, np.nan,   -4.0,   -4.1, np.nan, np.nan, np.nan] \n",
    "})\n",
    "vote_weird_exp = [1.0, 2.0, 3.0, 4.0, 4.1, 2.3, 1.3, 3.3]\n",
    "pres_weird_exp = [-1.0, -2.0, -3.0, -4.0, -4.1, -2.3, -1.3, -3.3]\n",
    "\n",
    "faithful_df = make_vote_supernodes(faithful_df, varnames=[\"VOTE{year}\", \"PRES{year}\"])\n",
    "faithful_df[\"VOTELASTEXP\"] = vote_faithful_exp\n",
    "faithful_df[\"PRESLASTEXP\"] = pres_faithful_exp\n",
    "\n",
    "print(faithful_df[\"VOTELAST\"].equals(faithful_df[\"VOTELASTEXP\"]))\n",
    "print(faithful_df[\"PRESLAST\"].equals(faithful_df[\"PRESLASTEXP\"]))\n",
    "\n",
    "weird_df = make_vote_supernodes(weird_df, varnames=[\"VOTE{year}\", \"PRES{year}\"])\n",
    "weird_df[\"VOTELASTEXP\"] = vote_weird_exp\n",
    "weird_df[\"PRESLASTEXP\"] = pres_weird_exp\n",
    "\n",
    "\n",
    "print(weird_df[\"VOTELAST\"].equals(weird_df[\"VOTELASTEXP\"]))\n",
    "print(weird_df[\"PRESLAST\"].equals(weird_df[\"PRESLASTEXP\"]))\n",
    "\n",
    "faithful_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NaN\n",
       "1      hello\n",
       "2    goodbye\n",
       "3        NaN\n",
       "4        NaN\n",
       "5        NaN\n",
       "6        NaN\n",
       "7        NaN\n",
       "Name: VOTE68, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faithful_df[\"VOTE68\"].map({1.1: \"hello\", 1.2: \"goodbye\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beliefs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
