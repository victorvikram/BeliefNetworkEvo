{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the belief network kitchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Packages we'll need. \"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pyreadstat as prs\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from clean_data_1 import transform_dataframe_1\n",
    "from clean_data_2 import transform_dataframe_2\n",
    "from make_belief_network import make_belief_network\n",
    "from make_belief_network import make_conditional_belief_network\n",
    "from get_basic_graph_info import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Importing the GSS dataset. \"\"\"\n",
    "\n",
    "raw_df, meta = prs.read_sas7bdat(\"../dat/gss7222_r3.sas7bdat\")\n",
    "\n",
    "\"\"\" Cleaning the data. \"\"\"\n",
    " \n",
    "df, metadata = transform_dataframe_1(raw_df)    # df contains all our data, metadata contains some other random shit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Setting the core replicating variables that we're interested in. \"\"\"\n",
    "\n",
    "variables = [\"PARTYID\",\"POLVIEWS\",\"NATSPAC\",\"NATENVIR\",\"NATHEAL\",\"NATCITY\",\"NATCRIME\",\"NATDRUG\",\"NATEDUC\",\"NATRACE\",\"NATARMS\",\n",
    "\"NATAID\",\"NATFARE\",\"NATROAD\",\"NATSOC\",\"NATMASS\",\"NATPARK\",\"NATCHLD\",\"NATSCI\",\"EQWLTH\",\"SPKATH\",\"COLATH\",\"LIBATH\",\"SPKRAC\",\"COLRAC\",\"LIBRAC\",\"SPKCOM\",\"COLCOM\",\"LIBCOM\",\"SPKMIL\",\"COLMIL\",\"LIBMIL\",\"SPKHOMO\",\n",
    "\"COLHOMO\",\"LIBHOMO\",\"SPKMSLM\",\"COLMSLM\",\"LIBMSLM\",\"CAPPUN\",\"GUNLAW\",\"COURTS\",\"GRASS\",\"ATTEND\",\"RELITEN\",\"POSTLIFE\",\"PRAYER\",\"AFFRMACT\",\"WRKWAYUP\",\"HELPFUL\",\n",
    "\"FAIR\",\"TRUST\",\"CONFINAN\",\"CONBUS\",\"CONCLERG\",\"CONEDUC\",\"CONFED\",\"CONLABOR\",\"CONPRESS\",\"CONMEDIC\",\"CONTV\",\"CONJUDGE\",\"CONSCI\",\"CONLEGIS\",\"CONARMY\",\"GETAHEAD\",\"FEPOL\",\"ABDEFECT\",\"ABNOMORE\",\"ABHLTH\",\"ABPOOR\",\"ABRAPE\",\"ABSINGLE\",\"ABANY\",\"SEXEDUC\",\"DIVLAW\",\"PREMARSX\",\"TEENSEX\",\"XMARSEX\",\"HOMOSEX\",\"PORNLAW\",\n",
    "\"SPANKING\",\"LETDIE1\",\"SUICIDE1\",\"SUICIDE2\",\"POLHITOK\",\"POLABUSE\",\"POLMURDR\",\"POLESCAP\",\"POLATTAK\",\"NEWS\",\"TVHOURS\",\"FECHLD\",\"FEPRESCH\",\"FEFAM\",\"RACDIF1\",\"RACDIF2\",\"RACDIF3\",\n",
    "\"RACDIF4\",\"HELPPOOR\",\"MARHOMO\", \"PRESLAST_NONCONFORM\", \"PRESLAST_DEMREP\", \"VOTELAST\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "NETWORK INFORMATION\n",
      "==================================================\n",
      "\n",
      "Top 5 Nodes by Degree Centrality:\n",
      "  1. HOMOSEX: 0.2871\n",
      "  2. PREMARSX: 0.2277\n",
      "  3. SUICIDE1: 0.1980\n",
      "  4. ATTEND: 0.1881\n",
      "  5. ABANY: 0.1782\n",
      "\n",
      "Top 5 Nodes by Betweenness Centrality:\n",
      "  1. HOMOSEX: 0.1706\n",
      "  2. CONCLERG: 0.0969\n",
      "  3. ATTEND: 0.0910\n",
      "  4. RACDIF4: 0.0899\n",
      "  5. POLVIEWS: 0.0893\n",
      "\n",
      "Top 5 Nodes by Eigenvector Centrality:\n",
      "  1. HOMOSEX: 0.3265\n",
      "  2. PREMARSX: 0.2913\n",
      "  3. SUICIDE1: 0.2683\n",
      "  4. PORNLAW: 0.2499\n",
      "  5. ABANY: 0.2390\n",
      "\n",
      "Number of Components: 11\n",
      "\n",
      "Basic Info:\n",
      "  - Size:           102\n",
      "  - Average Degree: 8.82\n",
      "\n",
      "Strongest Correlations:\n",
      "  1. PARTYID <--> PRESLAST_DEMREP (Strength: 0.4391)\n",
      "  2. SPKHOMO <--> COLHOMO (Strength: 0.3684)\n",
      "  3. ATTEND <--> RELITEN (Strength: 0.3321)\n",
      "  4. SPKMSLM <--> COLMSLM (Strength: 0.3251)\n",
      "  5. LETDIE1 <--> SUICIDE1 (Strength: 0.3033)\n",
      "\n",
      "Global Network Properties:\n",
      "  - Average Path Length:     inf\n",
      "  - Clustering Coefficient:  0.50\n",
      "  - Network Diameter:        inf\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Creating unconditioned belief networks. \"\"\"\n",
    "\n",
    "\"\"\" Belief networks are constructed for a given timeframe and set methodological parameters. \"\"\"\n",
    "\n",
    "# Timeframe - specify the start year and duration of the timeframe\n",
    "start_year = 1972\n",
    "duration = 2020 - start_year\n",
    "timeframe = list(range(start_year, start_year+duration))\n",
    "\n",
    "# Parameters\n",
    "method = \"spearman\"     # method for calculating correlation\n",
    "threshold = 0           # threshold for correlation\n",
    "sample_threshold = 0    # threshold for sample size\n",
    "regularisation = 0.2    # regularisation parameter for partial correlation\n",
    "\n",
    "\"\"\" Note: for now, we keep the threshold and sample threshold at 0. \n",
    "    Regularisation can be set between around 1.5 and 2.5. \"\"\"\n",
    "\n",
    "BN, variables_list, correlation_matrix_partial = make_belief_network(df, variables, timeframe, method=method, is_partial=True, threshold=threshold, \n",
    "                                                                     sample_threshold=sample_threshold, regularisation=regularisation)\n",
    "\n",
    "\"\"\" Print some basic information about the belief network. \"\"\"\n",
    "print_network_info(get_network_info(correlation_matrix_partial, variables_list))\n",
    "\n",
    "\"\"\" Save the graphml, correlation matrix (csv), variables list (csv). \"\"\"\n",
    "save = False\n",
    "if save:\n",
    "    name = f\"{start_year}-{start_year+duration}, R={regularisation}, Condition=None\"\n",
    "    output_dir = f\"../out/belief networks/{name}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    nx.write_graphml(BN, f\"{output_dir}/graph_object.graphml\", named_key_ids=True)\n",
    "    np.savetxt(f\"{output_dir}/correlation_matrix_partial.csv\", correlation_matrix_partial, delimiter=\",\")\n",
    "    np.savetxt(f\"{output_dir}/variables_list.csv\", variables_list, delimiter=\",\", fmt=\"%s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'graph': <networkx.classes.graph.Graph object at 0x000001CD8C1BC590>, 'vars': ['PARTYID', 'POLVIEWS', 'NATSPAC', 'NATENVIR', 'NATHEAL', 'NATCITY', 'NATCRIME', 'NATDRUG', 'NATEDUC', 'NATRACE', 'NATARMS', 'NATAID', 'NATFARE', 'NATROAD', 'NATSOC', 'NATMASS', 'NATPARK', 'NATCHLD', 'NATSCI', 'EQWLTH', 'SPKATH', 'COLATH', 'LIBATH', 'SPKRAC', 'COLRAC', 'LIBRAC', 'SPKCOM', 'COLCOM', 'LIBCOM', 'SPKMIL', 'COLMIL', 'LIBMIL', 'SPKHOMO', 'COLHOMO', 'LIBHOMO', 'CAPPUN', 'GUNLAW', 'COURTS', 'GRASS', 'ATTEND', 'RELITEN', 'POSTLIFE', 'PRAYER', 'AFFRMACT', 'WRKWAYUP', 'HELPFUL', 'FAIR', 'TRUST', 'CONFINAN', 'CONBUS', 'CONCLERG', 'CONEDUC', 'CONFED', 'CONLABOR', 'CONPRESS', 'CONMEDIC', 'CONTV', 'CONJUDGE', 'CONSCI', 'CONLEGIS', 'CONARMY', 'GETAHEAD', 'FEPOL', 'ABDEFECT', 'ABNOMORE', 'ABHLTH', 'ABPOOR', 'ABRAPE', 'ABSINGLE', 'ABANY', 'SEXEDUC', 'DIVLAW', 'PREMARSX', 'TEENSEX', 'XMARSEX', 'HOMOSEX', 'PORNLAW', 'SPANKING', 'LETDIE1', 'SUICIDE1', 'SUICIDE2', 'POLHITOK', 'POLABUSE', 'POLMURDR', 'POLESCAP', 'POLATTAK', 'NEWS', 'TVHOURS', 'FECHLD', 'FEPRESCH', 'FEFAM', 'RACDIF1', 'RACDIF2', 'RACDIF3', 'RACDIF4', 'HELPPOOR', 'PRESLAST_NONCONFORM', 'PRESLAST_DEMREP', 'VOTELAST'], 'corr_mat': array([[ 1.,  0., -0., ...,  0.,  0., -0.],\n",
      "       [ 0.,  1.,  0., ..., -0.,  0., -0.],\n",
      "       [-0.,  0.,  1., ..., -0., -0., -0.],\n",
      "       ...,\n",
      "       [ 0., -0., -0., ...,  1., -0.,  0.],\n",
      "       [ 0.,  0., -0., ..., -0.,  1.,  0.],\n",
      "       [-0., -0., -0., ...,  0.,  0.,  1.]])}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(conditioned_BN)\n\u001b[0;32m     25\u001b[0m conditioned_variables_list \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 26\u001b[0m conditioned_correlation_matrix \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "\"\"\" Creating conditioned belief networks. \"\"\"\n",
    "\n",
    "# Timeframe - specify the start year and duration of the timeframe\n",
    "start_year = 2000\n",
    "duration = 4\n",
    "timeframe = list(range(start_year, start_year+duration))\n",
    "\n",
    "# Conditioning - specify a list of variables to condition on and a list of corresponding values\n",
    "conditioning = \"PARTYID\"\n",
    "contidion_method = \"negpos\" # \"negpos\" (bins the variable to negative or positive and creates two BNs) or \"unique\" (ceates a BN for each unique value of the variable)\n",
    "\n",
    "# Parameters\n",
    "method = \"spearman\"     # method for calculating correlation\n",
    "threshold = 0           # threshold for correlation\n",
    "sample_threshold = 0    # threshold for sample size\n",
    "regularisation = 0.2    # regularisation parameter for partial correlation\n",
    "\n",
    "\n",
    "conditioned_BN, conditioned_variables_list, conditioned_correlation_matrix_partial = make_conditional_belief_network(conditioning, df, condition_method=contidion_method, variables_of_interest=variables, \n",
    "                                                                                 years_of_interest=timeframe, method=method, is_partial=True, threshold=threshold, \n",
    "                                                                                 sample_threshold=sample_threshold, regularisation=regularisation)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
