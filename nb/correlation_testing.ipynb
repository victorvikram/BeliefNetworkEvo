{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "617c44a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pingouin import partial_corr\n",
    "from pingouin import pairwise_corr\n",
    "\n",
    "from corr_networks import pairwise_correlations\n",
    "from corr_networks import pairwise_polychoric_correlations\n",
    "from corr_networks import precision_mat_to_partial_corr\n",
    "from corr_networks import cov_mat_to_regularized_partial_corr\n",
    "from corr_networks import my_pairwise_correlations\n",
    "\n",
    "from data_metadata import load_gss_sas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d36cd943",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss_file = \"C:/Users/vicvi/big-datasets/social_values/GSS_sas/gss7222_r3.sas7bdat\"\n",
    "variable_list = [\"VOTE68\", \"PARTYID\", \"POLVIEWS\", \"HOMOSEX\"]\n",
    "\n",
    "df, meta = load_gss_sas(gss_file, variable_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cd5a991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3\n",
      "0  1.628361 -0.259324 -1.050410 -0.527896\n",
      "1  3.205095 -0.699433 -0.934915 -0.493218\n",
      "2  1.279144 -0.314402  0.753300  0.314517\n",
      "3  0.191228  0.125083  0.773049 -0.384813\n",
      "4  2.365126 -0.484185 -0.996463 -0.869565\n",
      "   0  1  2  3\n",
      "0  4  0  4  0\n",
      "1  4  0  4  0\n",
      "2  4  0  6  1\n",
      "3  4  4  6  0\n",
      "4  4  0  4  0\n",
      "Cov mat\n",
      "[[ 1.54695214 -0.26597986 -0.30160722 -0.3323204 ]\n",
      " [-0.26597986  0.09889098 -0.03375579 -0.10324549]\n",
      " [-0.30160722 -0.03375579  0.87176609  0.49419805]\n",
      " [-0.3323204  -0.10324549  0.49419805  0.76987995]]\n",
      "Corr mat\n",
      "[[ 1.         -0.68003609 -0.25971876 -0.30451385]\n",
      " [-0.68003609  1.         -0.11496614 -0.37418058]\n",
      " [-0.25971876 -0.11496614  1.          0.60323918]\n",
      " [-0.30451385 -0.37418058  0.60323918  1.        ]]\n",
      "Partial corr mat\n",
      "[[ 1.         -0.89846877  0.07968497 -0.76784893]\n",
      " [-0.89846877  1.          0.13712877 -0.79810409]\n",
      " [ 0.07968497  0.13712877  1.          0.44953927]\n",
      " [-0.76784893 -0.79810409  0.44953927  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Define mean vector and covariance matrix\n",
    "dim = 4\n",
    "random_mat = 2 * np.random.rand(dim, dim) - 1 # get a matrix\n",
    "random_cov_mat = np.dot(random_mat, random_mat.T) # make it pos semi-definite\n",
    "\n",
    "std_deviations = np.sqrt(np.diag(random_cov_mat))\n",
    "random_cor_mat = random_cov_mat / np.outer(std_deviations, std_deviations)\n",
    "    \n",
    "mean = np.zeros((dim,))  # Mean vector\n",
    "\n",
    "# Generate random samples from the multivariate normal distribution\n",
    "num_samples = 5000\n",
    "samples = np.random.multivariate_normal(mean, random_cov_mat, size=num_samples)\n",
    "\n",
    "sample_df = pd.DataFrame(samples)\n",
    "\n",
    "# Print the first few samples\n",
    "\n",
    "precision_matrix = np.linalg.inv(random_cov_mat)\n",
    "partial_corr_mat = precision_mat_to_partial_corr(precision_matrix)\n",
    "\n",
    "sample_df_ord = pd.DataFrame()\n",
    "\n",
    "for var in list(range(dim)):\n",
    "    num_ordinal_values = np.random.randint(2, 11)\n",
    "    # signed = np.random.rand() > 0.5\n",
    "    var_std = np.sqrt(random_cov_mat[var, var])\n",
    "\n",
    "    interval_spread = np.random.rand() * var_std\n",
    "    leftmost_border = interval_spread * ((num_ordinal_values - 2)/ 2) + (np.random.rand() - 0.5)\n",
    "    \n",
    "    cutoffs = interval_spread * np.arange(num_ordinal_values - 1) - leftmost_border\n",
    "    cutoffs = np.concatenate(([-np.inf], cutoffs, [np.inf]))\n",
    "    sample_df_ord[var] = pd.cut(sample_df[var], bins=cutoffs, labels=np.arange(num_ordinal_values)).cat.codes\n",
    "\n",
    "\n",
    "print(sample_df.head())\n",
    "print(sample_df_ord.head())\n",
    "\n",
    "print(\"Cov mat\")\n",
    "print(random_cov_mat)\n",
    "\n",
    "print(\"Corr mat\")\n",
    "print(random_cor_mat)\n",
    "\n",
    "print(\"Partial corr mat\")\n",
    "print(partial_corr_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "126ea062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polychoric_partial_corr\n",
      "[[ 1.         -0.90986514  0.05393421 -0.78272285]\n",
      " [-0.90986514  1.          0.11767968 -0.81152128]\n",
      " [ 0.05393421  0.11767968  1.          0.42499887]\n",
      " [-0.78272285 -0.81152128  0.42499887  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# polychoric procedure \n",
    "polychoric_corr_mat = pairwise_polychoric_correlations([0, 1, 2, 3], sample_df_ord)\n",
    "polychoric_partial_corr_mat = cov_mat_to_regularized_partial_corr(polychoric_corr_mat)\n",
    "print(\"polychoric_partial_corr\")\n",
    "print(polychoric_partial_corr_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "42182753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.8978681 ,  0.06998312, -0.7674722 ],\n",
       "       [-0.8978681 ,  1.        ,  0.12756936, -0.79385832],\n",
       "       [ 0.06998312,  0.12756936,  1.        ,  0.44069435],\n",
       "       [-0.7674722 , -0.79385832,  0.44069435,  1.        ]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pearson procedure 1 on original data\n",
    "my_pairwise_correlations(list(range(dim)), sample_df, method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "80cd493c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.8978681 ,  0.06998312, -0.7674722 ],\n",
       "       [-0.8978681 ,  1.        ,  0.12756936, -0.79385832],\n",
       "       [ 0.06998312,  0.12756936,  1.        ,  0.44069435],\n",
       "       [-0.7674722 , -0.79385832,  0.44069435,  1.        ]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pearson procedure 2 on original data\n",
    "pearson_corr_df, pearson_corr_mat = pairwise_correlations(list(range(dim)), sample_df, \"pearson\")\n",
    "pearson_corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c8981f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.85919144,  0.01690616, -0.69490074],\n",
       "       [-0.85919144,  1.        ,  0.079675  , -0.72644659],\n",
       "       [ 0.01690616,  0.079675  ,  1.        ,  0.42953566],\n",
       "       [-0.69490074, -0.72644659,  0.42953566,  1.        ]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spearman procedure 1 on original data\n",
    "my_pairwise_correlations(list(range(dim)), sample_df, method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e5277032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.85919144,  0.01690616, -0.69490074],\n",
       "       [-0.85919144,  1.        ,  0.079675  , -0.72644659],\n",
       "       [ 0.01690616,  0.079675  ,  1.        ,  0.42953566],\n",
       "       [-0.69490074, -0.72644659,  0.42953566,  1.        ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spearman procedure 2 on original data\n",
    "spearman_corr_df, spearman_corr_mat = pairwise_correlations(list(range(dim)), sample_df, \"spearman\")\n",
    "spearman_corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7991b81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.6166378 , -0.10222241, -0.36117204],\n",
       "       [-0.6166378 ,  1.        , -0.00269639, -0.4182649 ],\n",
       "       [-0.10222241, -0.00269639,  1.        ,  0.4415108 ],\n",
       "       [-0.36117204, -0.4182649 ,  0.4415108 ,  1.        ]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spearman procedure 1 on ordinalized data\n",
    "my_pairwise_correlations(list(range(dim)), sample_df_ord, method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "10263133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.6166378 , -0.10222241, -0.36117204],\n",
       "       [-0.6166378 ,  1.        , -0.00269639, -0.4182649 ],\n",
       "       [-0.10222241, -0.00269639,  1.        ,  0.4415108 ],\n",
       "       [-0.36117204, -0.4182649 ,  0.4415108 ,  1.        ]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spearman procedure 2 on ordinalized data\n",
    "spearman_corr_df, spearman_corr_mat = pairwise_correlations(list(range(dim)), sample_df_ord, \"spearman\")\n",
    "spearman_corr_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2077c1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.99923368  0.99857396]\n",
      " [ 0.99923368  1.         -0.99691586]\n",
      " [ 0.99857396 -0.99691586  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "pearson_corr_df, pearson_corr_mat = partial_correlations(list(range(dim)), sample_df, \"pearson\")\n",
    "print(pearson_corr_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33f76e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.53125325,  0.58348842,  0.63130475],\n",
       "       [ 0.53125325,  1.        , -0.27885483, -0.14230966],\n",
       "       [ 0.58348842, -0.27885483,  1.        , -0.01317824],\n",
       "       [ 0.63130475, -0.14230966, -0.01317824,  1.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearman_corr_df, spearman_corr_mat = partial_correlations(list(range(dim)), sample_df_ord, \"spearman\")\n",
    "spearman_corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e1558ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.concat(corr_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1fd768a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>r</th>\n",
       "      <th>CI95%</th>\n",
       "      <th>p-val</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spearman</th>\n",
       "      <td>5000</td>\n",
       "      <td>-0.033487</td>\n",
       "      <td>[-0.06, -0.01]</td>\n",
       "      <td>0.017909</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             n         r           CI95%     p-val  x  y\n",
       "spearman  5000 -0.033487  [-0.06, -0.01]  0.017909  2  3"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d20f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_metadata import load_gss_sas\n",
    "\n",
    "\n",
    "\n",
    "load_gss_sas(filename, vars_to_load, metadataonly=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beliefs",
   "language": "python",
   "name": "beliefs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
